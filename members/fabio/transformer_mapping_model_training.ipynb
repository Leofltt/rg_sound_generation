{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "transformer_mapping_model_training.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PcAvS4amzDrZ"
      },
      "source": [
        "# Mapping model training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0fVn8yUJl_v"
      },
      "source": [
        "## Setup Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m33xuTjEKazJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06aceed0-77b8-4a0e-edca-7bbf91fd0fd9"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vn7CQ4GQizHy"
      },
      "source": [
        "## Install Dependencies\n",
        "\n",
        "First we install the required dependencies with `pip`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjhdKFJbvRVU"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "!pip install -qU ddsp[data_preparation]==1.0.1"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LVV4Dc61HHY"
      },
      "source": [
        "## Make directories to save model and data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9XJcymGj1IwY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a63bed2c-ffe3-4022-c69a-f6c12ec3c69d"
      },
      "source": [
        "import os\n",
        "\n",
        "drive_dir = '/content/drive/My Drive/nsynth_guitar'\n",
        "checkpoint_dir = os.path.join(drive_dir, 'mapping/checkpoint')\n",
        "\n",
        "assert os.path.exists(drive_dir)\n",
        "print('Drive Directory Exists:', drive_dir)\n",
        "\n",
        "!mkdir -p \"$checkpoint_dir\""
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive Directory Exists: /content/drive/My Drive/nsynth_guitar\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fgGZzyMGyA4"
      },
      "source": [
        "## Clear existing checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYaZoeNeGrvo"
      },
      "source": [
        "import shutil\n",
        "\n",
        "try:\n",
        "    shutil.rmtree(checkpoint_dir)\n",
        "except OSError as e:\n",
        "    print(\"Error: %s : %s\" % (checkpoint_dir, e.strerror))"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxRUhnmKsUj9"
      },
      "source": [
        "### Download Complete NSynth Guitar Subset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTVOibF9sb3y"
      },
      "source": [
        "dataset_dir = '/content/complete'\n",
        "train_dataset_dir = os.path.join(dataset_dir, 'train')\n",
        "valid_dataset_dir = os.path.join(dataset_dir, 'valid')\n",
        "test_dataset_dir = os.path.join(dataset_dir, 'test')\n",
        "\n",
        "train_tfrecord_file = os.path.join(train_dataset_dir, 'complete.tfrecord')\n",
        "valid_tfrecord_file = os.path.join(valid_dataset_dir, 'complete.tfrecord')\n",
        "test_tfrecord_file = os.path.join(test_dataset_dir, 'complete.tfrecord')\n",
        "\n",
        "if not os.path.exists(dataset_dir):\n",
        "  train = 'https://osr-tsoai.s3.amazonaws.com/complete/train/complete.tfrecord'\n",
        "  valid = 'https://osr-tsoai.s3.amazonaws.com/complete/valid/complete.tfrecord'\n",
        "  test = 'https://osr-tsoai.s3.amazonaws.com/complete/test/complete.tfrecord'\n",
        "\n",
        "  print(\"Downloading train dataset to {}\\n\".format(train_dataset_dir))\n",
        "  !mkdir -p \"$train_dataset_dir\"\n",
        "  !curl $train --output $train_tfrecord_file\n",
        "\n",
        "  print(\"\\nDownloading valid dataset to {}\\n\".format(valid_dataset_dir))\n",
        "  !mkdir -p \"$valid_dataset_dir\"\n",
        "  !curl $valid --output $valid_tfrecord_file\n",
        "\n",
        "  print(\"\\nDownloading test dataset to {}\\n\".format(test_dataset_dir))\n",
        "  !mkdir -p \"$test_dataset_dir\"\n",
        "  !curl $test --output $test_tfrecord_file"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9AWf8NpBiB4"
      },
      "source": [
        "## Define DataProvider class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6180WP6AkkJ"
      },
      "source": [
        "import tensorflow as tf\n",
        "import ddsp.training.data as data\n",
        "\n",
        "class CompleteTFRecordProvider(data.RecordProvider):\n",
        "  def __init__(self,\n",
        "               file_pattern=None,\n",
        "               example_secs=4,\n",
        "               sample_rate=16000,\n",
        "               frame_rate=250,\n",
        "               map_func=None):\n",
        "    super().__init__(file_pattern, example_secs, sample_rate,\n",
        "                      frame_rate, tf.data.TFRecordDataset)\n",
        "    self._map_func = map_func\n",
        "\n",
        "  def get_dataset(self, shuffle=True):\n",
        "    def parse_tfexample(record):\n",
        "      features = tf.io.parse_single_example(record, self.features_dict)\n",
        "      if self._map_func is not None:\n",
        "        return self._map_func(features)\n",
        "      else:\n",
        "        return features\n",
        "\n",
        "    filenames = tf.data.Dataset.list_files(self._file_pattern, shuffle=shuffle)\n",
        "    dataset = filenames.interleave(\n",
        "        map_func=self._data_format_map_fn,\n",
        "        cycle_length=40,\n",
        "        num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "    dataset = dataset.map(parse_tfexample,\n",
        "                          num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "    return dataset\n",
        "\n",
        "  @property\n",
        "  def features_dict(self):\n",
        "    return {\n",
        "      'sample_name':\n",
        "        tf.io.FixedLenFeature([1], dtype=tf.string),\n",
        "      'note_number':\n",
        "        tf.io.FixedLenFeature([1], dtype=tf.int64),\n",
        "      'velocity':\n",
        "        tf.io.FixedLenFeature([1], dtype=tf.int64),\n",
        "      'instrument_source':\n",
        "        tf.io.FixedLenFeature([1], dtype=tf.int64),\n",
        "      'qualities':\n",
        "        tf.io.FixedLenFeature([10], dtype=tf.int64),\n",
        "      'audio':\n",
        "        tf.io.FixedLenFeature([self._audio_length], dtype=tf.float32),\n",
        "      'f0_hz':\n",
        "        tf.io.FixedLenFeature([self._feature_length], dtype=tf.float32),\n",
        "      'f0_confidence':\n",
        "        tf.io.FixedLenFeature([self._feature_length], dtype=tf.float32),\n",
        "      'loudness_db':\n",
        "        tf.io.FixedLenFeature([self._feature_length], dtype=tf.float32),\n",
        "      'f0_scaled':\n",
        "        tf.io.FixedLenFeature([self._feature_length], dtype=tf.float32),\n",
        "      'ld_scaled':\n",
        "        tf.io.FixedLenFeature([self._feature_length], dtype=tf.float32),\n",
        "      'z':\n",
        "        tf.io.FixedLenFeature([self._feature_length * 16], dtype=tf.float32),\n",
        "    }"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbUpwtyRB8wV"
      },
      "source": [
        "## Define features map function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NbXhqrZaB5rw"
      },
      "source": [
        "def features_map(features):\n",
        "    note_number = features['note_number']\n",
        "    velocity = features['velocity']\n",
        "    instrument_source = features['instrument_source']\n",
        "    qualities = features['qualities']\n",
        "    f0_scaled = features['f0_scaled']\n",
        "    ld_scaled = features['ld_scaled']\n",
        "    z = features['z']\n",
        "\n",
        "    sequence_length = f0_scaled.shape[0]\n",
        "\n",
        "    # compute outputs\n",
        "    f0_variation = f0_scaled * 127.0 - tf.cast(note_number, dtype=tf.float32)\n",
        "    f0_variation = tf.clip_by_value(f0_variation, -1.0, 1.0)\n",
        "    f0_variation = tf.expand_dims(f0_variation, axis=-1)\n",
        "    ld_scaled = tf.expand_dims(ld_scaled, axis=-1)\n",
        "    z = tf.reshape(z, shape=(sequence_length, 16))\n",
        "\n",
        "    # compute inputs\n",
        "    note_number = tf.squeeze(tf.one_hot(note_number, 128))\n",
        "    velocity = tf.squeeze(tf.one_hot(velocity, 128))\n",
        "    instrument_source = tf.squeeze(tf.one_hot(instrument_source, 3))\n",
        "    qualities = tf.cast(qualities, dtype=tf.float32)\n",
        "    input_z = tf.math.reduce_mean(z, axis=0)\n",
        "\n",
        "    # construct input output vectors\n",
        "    inputs = tf.concat(\n",
        "        [note_number, velocity, instrument_source, qualities, input_z],\n",
        "        axis=-1)\n",
        "\n",
        "    targets = tf.concat(\n",
        "        [f0_variation, ld_scaled, z],\n",
        "        axis=-1)\n",
        "\n",
        "    inputs = {\n",
        "        'inputs': inputs,\n",
        "        'targets': targets,\n",
        "    }\n",
        "\n",
        "    return inputs, targets"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7dYOU811Ni4"
      },
      "source": [
        "## Create datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBa055Xy1MIL"
      },
      "source": [
        "batch_size = 16\n",
        "example_secs = 4\n",
        "sample_rate = 16000\n",
        "frame_rate = 250\n",
        "\n",
        "# Create train dataset\n",
        "train_data_provider = CompleteTFRecordProvider(\n",
        "    file_pattern=train_tfrecord_file + '*',\n",
        "    example_secs=example_secs,\n",
        "    sample_rate=sample_rate,\n",
        "    frame_rate=frame_rate,\n",
        "    map_func=features_map)\n",
        "\n",
        "train_dataset = train_data_provider.get_batch(\n",
        "    batch_size,\n",
        "    shuffle=True,\n",
        "    repeats=-1)\n",
        "\n",
        "# Create valid dataset\n",
        "valid_data_provider = CompleteTFRecordProvider(\n",
        "    file_pattern=valid_tfrecord_file + '*',\n",
        "    example_secs=example_secs,\n",
        "    sample_rate=sample_rate,\n",
        "    frame_rate=frame_rate,\n",
        "    map_func=features_map)\n",
        "\n",
        "valid_dataset = valid_data_provider.get_batch(\n",
        "    batch_size,\n",
        "    shuffle=True,\n",
        "    repeats=-1)\n",
        "\n",
        "# Create test dataset\n",
        "test_data_provider = CompleteTFRecordProvider(\n",
        "    file_pattern=test_tfrecord_file + '*',\n",
        "    example_secs=example_secs,\n",
        "    sample_rate=sample_rate,\n",
        "    frame_rate=frame_rate,\n",
        "    map_func=features_map)\n",
        "\n",
        "test_dataset = test_data_provider.get_batch(\n",
        "    batch_size,\n",
        "    shuffle=True,\n",
        "    repeats=-1)"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVxCGOXOY4Ab"
      },
      "source": [
        "# Transformer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sha2F2FdZDOJ"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def create_look_ahead_mask(size):\n",
        "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
        "    return mask  # (seq_len, seq_len)\n",
        "\n",
        "def get_angles(pos, i, d_model):\n",
        "    angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(d_model))\n",
        "    return pos * angle_rates\n",
        "\n",
        "\n",
        "def positional_encoding(position, d_model):\n",
        "    angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
        "                            np.arange(d_model)[np.newaxis, :],\n",
        "                            d_model)\n",
        "\n",
        "    # apply sin to even indices in the array; 2i\n",
        "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
        "\n",
        "    # apply cos to odd indices in the array; 2i+1\n",
        "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
        "\n",
        "    pos_encoding = angle_rads[np.newaxis, ...]\n",
        "\n",
        "    return tf.cast(pos_encoding, dtype=tf.float32)\n",
        "\n",
        "\n",
        "def scaled_dot_product_attention(q, k, v, mask):\n",
        "    \"\"\"Calculate the attention weights.\n",
        "    q, k, v must have matching leading dimensions.\n",
        "    k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
        "    The mask has different shapes depending on its type(padding or look ahead)\n",
        "    but it must be broadcastable for addition.\n",
        "\n",
        "    Args:\n",
        "      q: query shape == (..., seq_len_q, depth)\n",
        "      k: key shape == (..., seq_len_k, depth)\n",
        "      v: value shape == (..., seq_len_v, depth_v)\n",
        "      mask: Float tensor with shape broadcastable\n",
        "            to (..., seq_len_q, seq_len_k). Defaults to None.\n",
        "\n",
        "    Returns:\n",
        "      output, attention_weights\n",
        "    \"\"\"\n",
        "\n",
        "    matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
        "\n",
        "    # scale matmul_qk\n",
        "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
        "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
        "\n",
        "    # add the mask to the scaled tensor.\n",
        "    if mask is not None:\n",
        "        scaled_attention_logits += (mask * -1e9)\n",
        "\n",
        "    # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
        "    # add up to 1.\n",
        "    # (..., seq_len_q, seq_len_k)\n",
        "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)\n",
        "\n",
        "    # (..., seq_len_q, depth_v)\n",
        "    output = tf.matmul(attention_weights, v)\n",
        "\n",
        "    return output, attention_weights\n",
        "\n",
        "\n",
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.d_model = d_model\n",
        "\n",
        "        assert d_model % self.num_heads == 0\n",
        "\n",
        "        self.depth = d_model // self.num_heads\n",
        "\n",
        "        self.wq = tf.keras.layers.Dense(d_model)\n",
        "        self.wk = tf.keras.layers.Dense(d_model)\n",
        "        self.wv = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "        self.dense = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "    def split_heads(self, x, batch_size):\n",
        "        \"\"\"Split the last dimension into (num_heads, depth).\n",
        "        Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
        "        \"\"\"\n",
        "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
        "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "\n",
        "    def call(self, v, k, q, mask):\n",
        "        batch_size = tf.shape(q)[0]\n",
        "\n",
        "        q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
        "        k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
        "        v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
        "\n",
        "        # (batch_size, num_heads, seq_len_q, depth)\n",
        "        q = self.split_heads(q, batch_size)\n",
        "        # (batch_size, num_heads, seq_len_k, depth)\n",
        "        k = self.split_heads(k, batch_size)\n",
        "        # (batch_size, num_heads, seq_len_v, depth)\n",
        "        v = self.split_heads(v, batch_size)\n",
        "\n",
        "        # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
        "        # attention_weights.shape ==\n",
        "        # (batch_size, num_heads, seq_len_q, seq_len_k)\n",
        "        scaled_attention, attention_weights = scaled_dot_product_attention(\n",
        "            q, k, v, mask)\n",
        "\n",
        "        # (batch_size, seq_len_q, num_heads, depth)\n",
        "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
        "\n",
        "        # (batch_size, seq_len_q, d_model)\n",
        "        concat_attention = tf.reshape(scaled_attention,\n",
        "                                      (batch_size, -1, self.d_model))\n",
        "\n",
        "        # (batch_size, seq_len_q, d_model)\n",
        "        output = self.dense(concat_attention)\n",
        "\n",
        "        return output, attention_weights\n",
        "\n",
        "\n",
        "def point_wise_feed_forward_network(d_model, dff):\n",
        "    return tf.keras.Sequential([\n",
        "        # (batch_size, seq_len, dff)\n",
        "        tf.keras.layers.Dense(dff, activation='relu'),\n",
        "        # (batch_size, seq_len, d_model)\n",
        "        tf.keras.layers.Dense(d_model)\n",
        "    ])\n",
        "\n",
        "\n",
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "\n",
        "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
        "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "\n",
        "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "    def call(self, x, training, mask):\n",
        "        # (batch_size, input_seq_len, d_model)\n",
        "        attn_output, _ = self.mha(x, x, x, mask)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        # (batch_size, input_seq_len, d_model)\n",
        "        out1 = self.layernorm1(x + attn_output)\n",
        "\n",
        "        # (batch_size, input_seq_len, d_model)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        # (batch_size, input_seq_len, d_model)\n",
        "        out2 = self.layernorm2(out1 + ffn_output)\n",
        "\n",
        "        return out2\n",
        "\n",
        "\n",
        "class DecoderLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "\n",
        "        self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
        "        self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
        "\n",
        "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "\n",
        "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "        self.dropout3 = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "    def call(self, x, enc_output, training,\n",
        "             look_ahead_mask, padding_mask):\n",
        "        # enc_output.shape == (batch_size, input_seq_len, d_model)\n",
        "\n",
        "        # (batch_size, target_seq_len, d_model)\n",
        "        attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)\n",
        "        attn1 = self.dropout1(attn1, training=training)\n",
        "        out1 = self.layernorm1(attn1 + x)\n",
        "\n",
        "        attn2, attn_weights_block2 = self.mha2(\n",
        "            enc_output, enc_output, out1,\n",
        "            padding_mask)  # (batch_size, target_seq_len, d_model)\n",
        "        attn2 = self.dropout2(attn2, training=training)\n",
        "        out2 = self.layernorm2(\n",
        "            attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
        "\n",
        "        ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
        "        ffn_output = self.dropout3(ffn_output, training=training)\n",
        "        out3 = self.layernorm3(\n",
        "            ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n",
        "\n",
        "        return out3, attn_weights_block1, attn_weights_block2"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQaueb_AbcOK"
      },
      "source": [
        "def ffn(input_shape, num_layers, d_model, dff, rate=0.1):\n",
        "    inputs = tf.keras.layers.Input(shape=input_shape)\n",
        "    x = tf.keras.layers.Dense(dff)(inputs)\n",
        "    x = tf.keras.layers.LayerNormalization()(x)\n",
        "\n",
        "    for i in range(num_layers):\n",
        "        y = tf.keras.layers.Dense(dff, activation='relu')(x)\n",
        "        y = tf.keras.layers.Dropout(rate)(y)\n",
        "        x = tf.keras.layers.Add()([x, y])\n",
        "        x = tf.keras.layers.LayerNormalization()(x)\n",
        "\n",
        "    outputs = tf.keras.layers.Dense(d_model)(x)\n",
        "    return tf.keras.Model(inputs, outputs)\n",
        "\n",
        "\n",
        "class Encoder(tf.keras.layers.Layer):\n",
        "    def __init__(self, num_inputs, num_layers, d_model, dff, rate=0.1):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        self.ffn = ffn(\n",
        "            input_shape=(num_inputs,),\n",
        "            num_layers=num_layers,\n",
        "            d_model=d_model,\n",
        "            dff=dff,\n",
        "            rate=rate)\n",
        "\n",
        "    def call(self, x, training):\n",
        "        return self.ffn(x, training=training)\n",
        "\n",
        "\n",
        "class Decoder(tf.keras.layers.Layer):\n",
        "    def __init__(self, num_outputs, num_layers, d_model, num_heads, dff,\n",
        "                 time_steps, rate=0.1):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding = ffn(\n",
        "            input_shape=(time_steps, num_outputs),\n",
        "            num_layers=4,\n",
        "            d_model=d_model,\n",
        "            dff=dff,\n",
        "            rate=rate)\n",
        "\n",
        "        self.pos_encoding = positional_encoding(time_steps, d_model)\n",
        "\n",
        "        self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate)\n",
        "                           for _ in range(num_layers)]\n",
        "        self.dropout = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "    def call(self, x, enc_output, training, look_ahead_mask):\n",
        "        seq_len = tf.shape(x)[1]\n",
        "        attention_weights = {}\n",
        "\n",
        "        # (batch_size, target_seq_len, d_model)\n",
        "        x = self.embedding(x, training=training)\n",
        "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "        x += self.pos_encoding[:, :seq_len, :]\n",
        "\n",
        "        x = self.dropout(x, training=training)\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            x, block1, block2 = self.dec_layers[i](x, enc_output, training,\n",
        "                                                   look_ahead_mask,\n",
        "                                                   None)\n",
        "\n",
        "            attention_weights['decoder_layer{}_block1'.format(i + 1)] = block1\n",
        "            attention_weights['decoder_layer{}_block2'.format(i + 1)] = block2\n",
        "\n",
        "        # x.shape == (batch_size, target_seq_len, d_model)\n",
        "        return x, attention_weights\n",
        "\n",
        "\n",
        "class Transformer(tf.keras.Model):\n",
        "    def __init__(self, num_layers, d_model, num_heads, dff, time_steps,\n",
        "                 num_inputs, num_outputs, rate=0.1):\n",
        "        super(Transformer, self).__init__()\n",
        "\n",
        "        self.look_ahead_mask = create_look_ahead_mask(time_steps)\n",
        "\n",
        "        self.encoder = Encoder(num_inputs, num_layers, d_model, dff, rate)\n",
        "\n",
        "        self.decoder = Decoder(num_outputs, num_layers, d_model, num_heads, dff,\n",
        "                               time_steps, rate)\n",
        "\n",
        "        self.final_layer = tf.keras.layers.Dense(num_outputs)\n",
        "\n",
        "    def call(self, inputs, training=None, mask=None):\n",
        "        inp = inputs['inputs']\n",
        "        tar = inputs['targets']\n",
        "\n",
        "        # (batch_size, inp_seq_len, d_model)\n",
        "        enc_output = self.encoder(inp, training)\n",
        "\n",
        "        # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
        "        dec_output, attention_weights = self.decoder(\n",
        "            tar, enc_output, training, self.look_ahead_mask)\n",
        "\n",
        "        # (batch_size, tar_seq_len, target_vocab_size)\n",
        "        final_output = self.final_layer(dec_output)\n",
        "\n",
        "        return final_output"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RlGxnlpUervM"
      },
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "  def __init__(self, d_model, warmup_steps=4000):\n",
        "    super(CustomSchedule, self).__init__()\n",
        "    \n",
        "    self.d_model = d_model\n",
        "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "    self.warmup_steps = warmup_steps\n",
        "    \n",
        "  def __call__(self, step):\n",
        "    arg1 = tf.math.rsqrt(step)\n",
        "    arg2 = step * (self.warmup_steps ** -1.5)\n",
        "    \n",
        "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTiP6aA82Uay"
      },
      "source": [
        "# Create and compile mapping model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26aSTwuy2ZKy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48951055-8c8c-47a2-abb2-1bfef52742d6"
      },
      "source": [
        "x_train, y_train = next(iter(train_dataset))\n",
        "\n",
        "num_inputs = x_train['inputs'].shape[-1]\n",
        "num_outputs = y_train.shape[-1]\n",
        "time_steps = y_train.shape[-2]\n",
        "\n",
        "print(num_inputs)\n",
        "print(num_outputs)\n",
        "print(time_steps)\n",
        "\n",
        "num_layers = 4\n",
        "d_model = 128\n",
        "num_heads = 4\n",
        "dff = 128\n",
        "\n",
        "model = Transformer(\n",
        "    num_layers=num_layers,\n",
        "    d_model=d_model,\n",
        "    num_heads=num_heads,\n",
        "    dff=dff,\n",
        "    time_steps=time_steps,\n",
        "    num_inputs=num_inputs,\n",
        "    num_outputs=num_outputs,\n",
        "    rate=0.1)\n",
        "\n",
        "loss = tf.keras.losses.MeanAbsoluteError()\n",
        "\n",
        "learning_rate = CustomSchedule(d_model)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, \n",
        "                                     epsilon=1e-9)\n",
        "\n",
        "model.compile(\n",
        "    optimizer=optimizer,  # tf.keras.optimizers.Adam(learning_rate=0.01),\n",
        "    loss=loss,\n",
        "    metrics=[tf.keras.losses.MeanSquaredError()])"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "285\n",
            "18\n",
            "1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "zOBxsJYCGf-2",
        "outputId": "895585a7-7a67-4a7f-cf1c-03c19858151a"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "temp_learning_rate_schedule = CustomSchedule(d_model)\n",
        "\n",
        "plt.plot(temp_learning_rate_schedule(tf.range(40000, dtype=tf.float32)))\n",
        "plt.ylabel(\"Learning Rate\")\n",
        "plt.xlabel(\"Train Step\")"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Train Step')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAEGCAYAAACtqQjWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxV9Z34/9c7OwlkIQlhCRAIYQmKqBH3peKC2sq0xRHqd2qro9NWu3esfjvjOP7q/GrbqdZW67jgNipQaiu27nXfgLiggCC5Nwhhy02ASMISkry/f5xP4BJvkpvk3tyb3Pfz8cgj537OOZ/zvjeQd875fM77iKpijDHGREJSrAMwxhgzeFhSMcYYEzGWVIwxxkSMJRVjjDERY0nFGGNMxKTEOoBYKigo0JKSkliHYYwxA8q7775bp6qFodYldFIpKSmhsrIy1mEYY8yAIiKfdrbOLn8ZY4yJGEsqxhhjIsaSijHGmIixpGKMMSZiLKkYY4yJmKgmFRGZIyLrRaRKRK4PsT5dRBa79ctFpCRo3Q2ufb2InB/UvlBEakVkdSfH/LGIqIgUROM9GWOM6VzUkoqIJAN3AhcA5cACESnvsNmVwC5VnQTcBtzq9i0H5gPTgTnAXa4/gAddW6hjjgXOAzZF9M0YY4wJSzTPVGYBVarqV9VmYBEwt8M2c4GH3PJSYLaIiGtfpKoHVLUaqHL9oaqvATs7OeZtwHXAoKznr6osWbmZxgMtsQ7FGGNCimZSGQNsDnpd49pCbqOqLUADkB/mvkcQkbnAFlVd1c12V4tIpYhUBgKBcN5H3Phg826u+9OH/HTph7EOxRhjQhoUA/Uikgn8X+DG7rZV1XtUtUJVKwoLQ1YZiFubdu4F4IWPd8Q4EmOMCS2aSWULMDbodbFrC7mNiKQAOUB9mPsGKwUmAKtEZKPb/j0RGdmH+OOOL9AEQHNLG5tdgjHGmHgSzaSyEigTkQkikoY38L6swzbLgMvd8jzgJfWeb7wMmO9mh00AyoAVnR1IVT9S1RGqWqKqJXiXy45T1e2RfUux5Qs0IuItP7N6W2yDMcaYEKKWVNwYybXAc8DHwBJVXSMiN4vIxW6z+4F8EakCfgRc7/ZdAywB1gLPAteoaiuAiDwOvA1MEZEaEbkyWu8h3vgDTZw5uZDpo7N5ZvWgypfGmEEiqlWKVfVp4OkObTcGLe8HLulk31uAW0K0LwjjuCU9jTXetbUp1XWNnFKazwklw/nVc+vZ1rCPUTlDYh2aMcYcMigG6hPB1oZ97D/YxsTCLOYc5Q0VPWtnK8aYOGNJZYDwu0H60sKhlBYOZerIYTy1amuMozLGmCNZUhkgfIFGACYWZgEwd+YY3tu0m0/rm2IZljHGHMGSygDhDzQxLCOFwqHpAMydORoR+Mv7drZijIkfllQGCF+gkYmFQxE3p3h07hBOmpDPn9+vwZuFbYwxsWdJZYDwB5ooLcg6ou3Lx41hY/1e3t+8O0ZRGWPMkSypDACNB1rY/tl+SkcMPaL9gqNGkp6SxF/e76rYgDHG9B9LKgNAtZv5NbHDmcqwjFTOLS/iqVVbOdDSGovQjDHmCJZUBgB/nTfzq+OZCsAlFWPZtfcgz6+xIpPGmNizpDIA+GobSRIYn5/5uXWnTyqgOG8Ijy2355IZY2LPksoA4Ktrojgvk/SU5M+tS0oSFswax9v+evzuXhZjjIkVSyoDgK+2kdLCrE7XX1JRTEqSsGjl5k63McaY/mBJJc61tSkb65uYWPj58ZR2I4ZlcM60Ipa+W2MD9saYmLKkEufaC0mWdpFUAL524jh2NjVbkUljTExZUolz7U97nNjF5S+A0yYVMKEgi4VvbrQ77I0xMWNJJc61D753d6aSlCR889QSVm3ezXubdvVHaMYY8zmWVOKcL9DIsIwUCoamdbvtvOOLyRmSyn2vV/dDZMYY83mWVOKcP9B0RCHJrmSmpbBg1jieW7OdzTv39kN0xhhzJEsqcc4faOpyOnFHl58yniQRHnxrY/SCMsaYTkQ1qYjIHBFZLyJVInJ9iPXpIrLYrV8uIiVB625w7etF5Pyg9oUiUisiqzv09SsRWSciH4rIn0UkN5rvrT8cKiTZzXhKsFE5Q7jw6FEsXrmZhr0HoxidMcZ8XtSSiogkA3cCFwDlwAIRKe+w2ZXALlWdBNwG3Or2LQfmA9OBOcBdrj+AB11bRy8AR6nqDOAT4IaIvqEYqD70COHwz1QAvn1WKY0HWnjgLRtbMcb0r2ieqcwCqlTVr6rNwCJgbodt5gIPueWlwGzxBg/mAotU9YCqVgNVrj9U9TVgZ8eDqerzqtriXr4DFEf6DfW3w48QDv9MBWDaqGzOmVbEA29uZM9+O1sxxvSfaCaVMUBw3ZAa1xZyG5cQGoD8MPftyhXAM6FWiMjVIlIpIpWBQKAHXfY/f6DzQpLd+d7sSTTsO8gj73wahciMMSa0QTdQLyI/A1qAR0OtV9V7VLVCVSsKCwv7N7ge8gWaGDs8dCHJ7swozuXMyYXc93o1e5tbut/BGGMiIJpJZQswNuh1sWsLuY2IpAA5QH2Y+36OiHwD+CJwmQ6C28p9gcbPPZirJ7579iR2NjXz6DtWFt8Y0z+imVRWAmUiMkFE0vAG3pd12GYZcLlbnge85JLBMmC+mx02ASgDVnR1MBGZA1wHXKyqA/4mjbY2pbquqUczvzqqKBnOaZMK+MOrPhtbMcb0i6glFTdGci3wHPAxsERV14jIzSJysdvsfiBfRKqAHwHXu33XAEuAtcCzwDWq2gogIo8DbwNTRKRGRK50ff0eGAa8ICIfiMjd0Xpv/WHL7n0caGnr8SB9Rz+dM5WdTc3c+5o/QpEZY0znUqLZuao+DTzdoe3GoOX9wCWd7HsLcEuI9gWdbD+pT8HGGX9d76YTd3R0cQ4XzRjFfW9U808nl1A4LD0S4RljTEiDbqB+sPDV9m46cSg/OW8KzS1t/O6lDX3uyxhjumJJJU7568IvJNmdCQVZXHrCWB5bvomN7gzIGGOiwZJKnPJqfoVXSDIc359dRnpKEj//28cR6c8YY0KxpBKnfIHGbh/M1RMjsjP47uwyXvx4B6+sr41Yv8YYE8ySShxqPNDCjs8O9Gk6cSjfPLWECQVZ3PzUWppb2iLatzHGgCWVuHT4aY+RO1MBSE9J5sYvleOva+JBKzZpjIkCSypxyH/oufSRPVMB+MKUEcyeOoLfvriB7Q37I96/MSaxWVKJQ74+FJIMx41fKqdVlX9/cjWDoJqNMSaOWFKJQ/4+FJIMx/j8LH54zmReWLuDZ1Zvj8oxjDGJyZJKHPIFGiM+SN/RladN4Kgx2dz45Bp7QqQxJmIsqcSZ9kKSfalOHI6U5CRu/eoMdu1t5pan10b1WMaYxGFJJc60F5IsHRHdMxWA6aNzuPqMiSyprOFlu3fFGBMBllTizKFHCEf5TKXd92eXMaVoGNct/ZD6xgP9ckxjzOBlSSXORHM6cSgZqcncPn8mDXsPcsMTH9lsMGNMn1hSiTP+ukayI1RIMlzTRmVz3ZwpPL92B0sqN/fbcY0xg48llTjjq21iYgQLSYbrilMncEppPv/51NpDd/QbY0xPWVKJM/666E8nDiUpSfjvfzyG9JQkvvPoe+xrbu33GIwxA58llTiyZ/9Bdnx2IKLViXtiVM4Qbrt0Jut37OHf/mJ32xtjes6SShypjtAjhPvirCkj+O7ZZfzpvRoWr7TxFWNMz0Q1qYjIHBFZLyJVInJ9iPXpIrLYrV8uIiVB625w7etF5Pyg9oUiUisiqzv0NVxEXhCRDe57XjTfWzT4DlUn7v/LX8G+P7uM08sKuHHZGlZvaYhpLMaYgSVqSUVEkoE7gQuAcmCBiJR32OxKYJeqTgJuA251+5YD84HpwBzgLtcfwIOuraPrgb+rahnwd/d6QPEHmkgSGBelQpLhSk4Sbr90JgVZaVz1cCW1e6yasTEmPNE8U5kFVKmqX1WbgUXA3A7bzAUecstLgdniTXuaCyxS1QOqWg1Uuf5Q1deAnSGOF9zXQ8A/RPLN9Ad/oIlxUSwk2RP5Q9O59/IKdu89yNUPv8v+gzZwb4zpXjSTyhgg+KJ8jWsLuY2qtgANQH6Y+3ZUpKrb3PJ2oCjURiJytYhUikhlIBAI5330G+8RwrG99BVs+ugcbp8/kw827+a6pR/awL0xpluDcqBevd9+IX8Dquo9qlqhqhWFhYX9HFnnWl0hyVgO0ody/vSRXDdnCstWbeV3L1XFOhxjTJyLZlLZAowNel3s2kJuIyIpQA5QH+a+He0QkVGur1HAgKqQuNUVkoynM5V23z6zlK8cN4bfvPAJS2xGmDGmC9FMKiuBMhGZICJpeAPvyzpsswy43C3PA15yZxnLgPludtgEoAxY0c3xgvu6HHgyAu+h3/R3IcmeEBF+8ZUZnDG5kOuf+JAX1u6IdUjGmDgVtaTixkiuBZ4DPgaWqOoaEblZRC52m90P5ItIFfAj3IwtVV0DLAHWAs8C16hqK4CIPA68DUwRkRoRudL19QvgXBHZAJzjXg8Y7YUk+6PkfW+kpSTxh8uO4+jiXK597D1WVIeaK2GMSXSSyIOvFRUVWllZGeswAPjZnz/iqVVbWfUf5/V73a+e2NnUzLy73yKw5wCLrz6Z8tHZsQ7JGNPPRORdVa0ItW5QDtQPRP5AE6Uj+r+QZE8Nz0rj4StmMTQ9hcvue4ePt30W65CMMXHEkkqc8AUamVgQn5e+OirOy+Txq04iPSWZy+5bzvrte2IdkjEmTlhSiQN79h+kdk/sCkn2RklBFo9ffRKpycLX7n2HDTsssRhjLKnEhUOD9HE4nbgrEwqyeOyqk0hOEhbca5fCjDGWVOKCv669kOTAOVNpV1o4lMevPomUpCQu/Z+3efdTmxVmTCLrNqmIyGQR+Xt7VWARmSEi/xb90BKHP9BEcpLEvJBkb5UWDmXpt08mf2g6l923nFfWD6j7To0xERTOmcq9wA3AQQBV/RDvRkYTIb5AI2PzhsRFIcneKs7LZMm/nMzEgqFc9XAlT63aGuuQjDExEE5SyVTVjnezt0QjmETlDzQNuPGUUAqHpbPoX07i2LF5fG/R+9zzms+KUBqTYMJJKnUiUoor0Cgi84BtXe9iwtXapvjrmgbUzK+uZGek8vCVs7jwqFH819Pr+L9/Xs3B1rZYh2WM6ScpYWxzDXAPMFVEtgDVwGVRjSqBbN29j+Y4LSTZWxmpyfxuwbGMz8/krld81Ozay52XHUd2RmqsQzPGRFk4ZyqqqucAhcBUVT0tzP1MGOLlEcKRlpQkXDdnKr+cN4O3ffV89a632FjXFOuwjDFRFk5y+BOAqjapavsdbkujF1Ji8bl7VAbL5a+O/rFiLA9fOYtA4wG+9Ps3+PvHVuHYmMGs06QiIlNF5KtAjoh8JejrG0BGv0U4yPkDjeQMSSU/Ky3WoUTNKaUFPHXtaYzPz+TKhyr5zfPraW2zAXxjBqOuxlSmAF8EcoEvBbXvAa6KZlCJxHuEcFbcF5Lsq7HDM1n6rVP497+s5o6XqlhV08Dtl84kbxAnU2MSUadJRVWfBJ4UkZNV9e1+jCmh+ANNnF4WP481jqaM1GR+OW8GM8flctOyNVx4x+vcdulMTpqYH+vQjDEREs6Yyvsico2I3CUiC9u/oh5ZAmgvJFk6YnCOp4QiIlx24nie+PapZKQms+Ded/jN8+tpsWnHxgwK4SSVR4CRwPnAq3jPi7eStBHQXkhyoJS8j6Sji3P463dP46vHFXPHS1Vces87bN65N9ZhGWP6KJykMklV/x1oUtWHgIuAE6MbVmJoLyQ5KYHOVIJlpafw60uO4Y4Fx/LJ9j1c+NvXWVK52e7CN2YACyepHHTfd4vIUUAOMCJ6ISUOX60rJDk8MZNKu4uPGc3T3z+daaOzuW7ph3zjgZVs3b0v1mEZY3ohnKRyj4jkAf8GLAPWArdGNaoE4a9rZNzwTNJS7F7SscMzWXTVSfznxdNZUb2T8297jcUrN9lZizEDTLe/zVT1PlXdpaqvqepEVR0BPBNO5yIyR0TWi0iViFwfYn26iCx265eLSEnQuhtc+3oROb+7PkVktoi8JyIfiMgbIjIpnBhjyVfbxMSCxD5LCZaUJFx+SgnP/eAMykdn89M/fcTXF66wO/GNGUC6TCoicrKIzBOREe71DBF5DHizu45FJBm4E7gAKAcWiEh5h82uBHap6iTgNtwZkNtuPjAdmAPcJSLJ3fT5B+AyVZ0JPIZ3ZhW3WtuU6vrBU0gyksblZ/L4VSdx89zpvL9pN+fd/hq/fXEDB1paYx2aMaYbXd1R/ytgIfBV4G8i8nPgeWA5UBZG37OAKlX1q2ozsAiY22GbucBDbnkpMFu8uwDnAotU9YCqVgNVrr+u+lQg2y3nAHH9QI/2QpKDreZXpCQlCV8/uYS///hMzisv4rYXP2HO7a/zxoa6WIdmjOlCV3fUXwQcq6r73ZjKZuAoVd0YZt9j3D7tavj8rLFD26hqi4g0APmu/Z0O+45xy531+c/A0yKyD/gMOClUUCJyNXA1wLhx48J8K5FX5QpJDqbqxNFQlJ3B7792HP9YEeDGJ1fzf+5fzhdnjOKGC6cxJndIrMMzxnTQ1eWv/aq6H0BVdwEbepBQYuGHwIWqWgw8APwm1Eaqeo+qVqhqRWFh7O5kb79HZSA+lz4WzphcyLM/OIMfnFPGC2t3cPavX+FXz62j8YA9L86YeNLVmcpEEVkW9HpC8GtVvbibvrcAY4NeF7u2UNvUiEgK3mWr+m72/Vy7iBQCx6jqcte+GHi2m/hiyucKSQ632ldhy0hN5gfnTOaSirH86tl13PmyjyWVNfzkvMnMO34syUmDu36aMQNBV0ml4/jHf/ew75VAmYhMwEsI84GvddhmGXA58DYwD3hJVdUlr8dE5DfAaLwxnBWAdNLnLrxqypNV9RPgXODjHsbbr/wJUkgyGsbkDuH2+cdy+Skl/PxvH/PTP33EA29u5PoLpnLm5EL7TI2Joa4KSr7al47dGMm1wHNAMrBQVdeIyM1ApaouA+4HHhGRKmAnXpLAbbcE756YFuAaVW0FCNWna78K+JOItOElmSv6En+0+QJNnDk5MQpJRsux4/JY+q2Tefqj7fzi2Y/5xgMrOaEkj5+cN4UTrUilMTEhiXxzWUVFhVZWVvb7cffsP8jRNz3PdXOm8J2z4v52mgGhuaWNxZWb+f1LG9jx2QFOLyvgJ+dN4ZixubEOzZhBR0TeVdWKUOvsVu4YODxIbzO/IiUtJYl/Omk8r/7rF/jZhdNYs/Uz5t75Jlc9XMmHNbtjHZ4xCaOrMRUTJYefS28zvyItIzWZq86YyIITx7HwjWrufd3PC2t3cHpZAdd8YRInThhuYy7GRFG3SUVEnsK7sTBYA1AJ/E/7tGMTPn/ACklG29D0FL43u4xvnlrC/76zifvf8DP/nnc4fnwe13yhlC9MGWHJxZgoCOfylx9oBO51X5/hPU9lsnttesgXsEKS/WVYRirfPquUN356NjfPnc72hv1c8WAlF/z2df78fg3NLfZwMGMiKZzLX6eo6glBr58SkZWqeoKIrIlWYIOZP2CFJPtbRmoyXz+5hAWzxvHkB1v5wytV/HDxKv7r6XV8/aTxfO3EceQPTY91mMYMeOH8qTxURA7VM3HL7SPMzVGJahBrLyRZOsIG6WMhNTmJeccX88IPz+TBb57AtFHZ/PcLn3DyL17ip0s/ZN32z2IdojEDWjhnKj8G3hARH97NhxOA74hIFoeLQZowbdnlFZK0M5XYSkoSzpoygrOmjGDDjj088NZGnnivhsWVmzmlNJ//c9J4zi0vIjXZLlEa0xPdJhVVfVpEyoCprml90OD87VGLbJDyuUcI25lK/CgrGsZ/fflo/vW8KTy+chP/+/anfOfR9ygYms4/VhSzYNY4xg7PjHWYxgwI4U4pPh4ocdsfIyKo6sNRi2oQ89W66sR2phJ38rLS+M5Zk/iXM0p59ZNaHlu+ibtf9fGHV32cXlbI12aNY/a0EXb2YkwXwplS/AhQCnwAtD8lSQFLKr3gr2siN9MKScaz5CTh7KlFnD21iK2797F45WYWr9zMt/73XQqHpfMPM0fzleOKmTYqu/vOjEkw4ZypVADlmsj1XCLIV9vIxAIrJDlQjM4dwg/Pncx3z57Ey+sD/LFyMw++tZF7X6+mfFQ2XzluDHNnjqFwmM0cMwbCSyqrgZHAtijHkhD8dVZIciBKSU7i3PIizi0vYmdTM0+t2soT79Xw8799zP//zDrOnFzIV44bwznTishITY51uMbETDhJpQBYKyIrgAPtjWE8T8V08Nn+gwT2HLCaXwPc8Kw0Lj+lhMtPKWHDjj088f4W/vzeFl5aV0tWWjLnlBdx0dGjOHNKIekplmBMYgknqdwU7SASRXshyYlW82vQKCsaxk/nTOUn503hHX89f/1wK8+s3s6TH2xlWHoK504v4oszRnHapEKroGASQjhTivv0XBVzmP9QIUk7UxlskpOEUycVcOqkAm6eexRv+er566qtPLdmO0+8t4XsjBTOnz6SC44eySmlBXaJzAxanSYVEXlDVU8TkT0cWVBSAFVVm/rSQ75Aoyskafc8DGapyUmcObmQMycXcsuXj+aNqgB/XbWNZ1Zv54/v1pCZlsyZkws5t7yIs6eOIDfTZgKawaOrJz+e5r4P679wBjd/oMkKSSaYtJSkQ9OTD7S08ravnufX7uDFtTt4ZvV2kpOEWSXDD00CsJsszUAX1pMfRSQZKCIoCanqpijG1S/6+8mP5932KuOGZ3Lf5Sd0v7EZ1NralA+3NPDC2u08v2YHG9xNsVNHDnPlYwo5fnye3Whp4lJXT34M5+bH7wL/AewA2uuEKzAjYhEmgNY2ZWP9Xs6aMiLWoZg4kJQkzByby8yxufzr+VPZWNfEC2t38OLHO7jvdT93v+pjaHoKp07K56wpIzhzciGjc4fEOmxjuhXO7K/vA1NUtb6nnYvIHOC3QDJwn6r+osP6dLw7848H6oFLVXWjW3cDcCXeXfzfU9XnuupTvLsJfw5c4vb5g6re0dOYo6W9kKQ97dGEUlKQxVVnTOSqMyayZ/9B3qyq59VPAry6vpbn1uwAYHLRUM6aMoIzygqpKMmzwX4Tl8JJKpvxnvTYI+6S2Z3AuUANsFJElqnq2qDNrgR2qeokEZkP3ApcKiLlwHxgOjAaeFFEJrt9OuvzG8BYYKqqtolIXJ0StD9CeKLN/DLdGJaRypyjRjLnqJGoKhtqG3llfS2vfhLggTeruec1P2kpSVSMz+OU0nxOmVTAjDE5pNilMhMHwkkqfuAVEfkbR978+Jtu9psFVKmqH0BEFgFzgeCkMpfD98EsBX7vzjjmAotU9QBQLSJVrj+66PPbwNdUtc3FVxvGe+s3PptObHpBRJhcNIzJRcO4+oxSmg608I6/nrd83tevn/8Env+EoekpnDhhOCeX5nPqpAKmFA0jKclKAZn+F05S2eS+0txXuMbgneW0qwFO7GwbVW0RkQYg37W/02HfMW65sz5L8c5yvgwE8C6ZbegYlIhcDVwNMG7cuI6ro8YXsEKSpu+y0lOYPa2I2dOKANjZ1Mzbvnre8tXxlq+ev6/z/pbKz0rjxInDOaHE+5o2KptkSzKmH3SZVNwlrMmqelk/xdMX6cB+Va0Qka8AC4HTO26kqvcA94A3+6u/gvMHGq3cvYm44VlpXDRjFBfNGAXA1t37eNtXz5u+Opb7d/L0R9sBGJqewnHj85hVkscJJcM5ZmyujcmYqOgyqahqq4iMF5E0Ve3po4O34I1xtCt2baG2qRGRFCAHb8C+q307a68BnnDLfwYe6GG8UeWva+IsKyRpomx07hC+enwxXz2+GPCSzMqNO72v6l3e5TIgLTmJGcU5VJQMZ9aEPGaOzbOzaBMR4Y6pvCkiy4Cm9sYwxlRWAmUiMgHvF/984GsdtlkGXA68DcwDXlJVdcd6TER+gzdQXwaswLubv7M+/wJ8AagGzgQ+CeO99Yv2QpI2SG/62+jcIcyd6ZXnB9i9t5nKjbtYuXEnKzbudNOXvRP2kvxMZo7N5dhxecwcm8u0Udl2o67psXCSis99JQFh313vxkiuBZ7Dm/67UFXXiMjNQKWqLgPuBx5xA/E78ZIEbrsleAPwLcA1qtoKEKpPd8hfAI+KyA+BRuCfw4012toLSdp0YhNruZlpnFNexDnl3pjMvuZWVtXs5oPNu/lg027e8tXzlw+2Al41gKPH5LhE491TMyZ3iD0LyHQprDvqB6v+uqP+T+/W8OM/ruLFH53JJHs2vYljqsq2hv18sHk372/axfubdvPRlgYOtHj3PRcOS2fGmByOcl9Hj8mhKDvdEk2C6esd9YXAdXj3jGS0t6vq2RGLcJDz11khSTMwiAijc4cwOncIFx7tDf4fbG1j3bY9vL95Fx+4JPPy+lra3N+jBUPTOWpMNkcHJZpRORmWaBJUOJe/HgUWA18EvoU3BhKIZlCDja+2ifFWSNIMUKnJSRxdnMPRxTl8/WSvbW9zC2u3fsbqLQ18tMX7/tongUOJJj8rjeljcjh6TDbTRmUzdWQ2JfmZdoNmAggnqeSr6v0i8n33bJVXRWRltAMbTPx1jfZgLjOoZKalUFEynIqS4Yfa9jW38vF2l2hqGvhoSwN3V9XR6jJNekoSk4uGMXXkMC/RjBrGtJHZ5Nmss0ElnKRy0H3fJiIXAVuB4V1sb4K0tikb6/byBSskaQa5IWnJHDcuj+PG5R1q23+wlaraRtZt38O6bZ+xbvseXlpXyx/frTm0TVF2OlNHHk4yU0cNo7RwqFVoHqDCSSo/F5Ec4MfA74Bs4IdRjWoQqdm1l+bWNjtTMQkpIzX50KB+sMCeA6zb/hnrtu3hY/f9bV89za3ehIDUZGFCQRZlI4ZROmIoZSOGUlY0lAkFWaSn2E2b8Sycxwn/1S024N0HYnrg8HRim/VlTLvCYekUDivk9LLDNwQfbG2juq6Jj90ZzYYdjazd9hnPrN52aKwmSWB8fhaTghLNpMJhlI7IIjMtnL+RTcx/dBMAABPjSURBVLSFM/trMvAHoEhVjxKRGcDFqvrzqEc3CFh1YmPCk5qcdKh45tyg9v0HW6mua2JDbSNVO/awobaRDbWNvLyulpa2w7dEFOcNoWzEUEoLhzKhMIsJBVlMLBhqU577WTip/V7gX4H/AVDVD0XkMbxnl5huWCFJY/omIzWZaaO8WWTBDra28Wl9Ext2NB5KNBt27OEtX/2h+2oAMtOSKcnPYkJhFhMLvGTTnnByMlP7++0MeuEklUxVXdEh07dEKZ5Bxx9otEtfxkRBanISk0YMY9KIYVwQ1N7Wpmz7bD/VgSaq6xrx1zVRXdfE6i0NPPPR4Utp4BXknBCUaCYUZDFueCbj8jPJzrCE0xvhJJU6ESnFe4QwIjIP2BbVqAYRX6CJL0yxQpLG9JekJGFM7hDG5A7htLKCI9Y1t7Sxaedequu8hFPtEs7rGwIsDZqRBpCbmcr44ZmMHZ7J+PxMxh1azmJkdoY9SqAT4SSVa/BKxU8VkS14BRsHQin8mGvYd5C6xgOUWmkWY+JCWkoSk0YMdeWSio5Y13ighU31e9m0s4lNO/fyaf1eNu3cy0dbGnh29fYjxm/SkpMozhtyRMJpP8MZkzuEYQl8lhPO7C8/cI6IZAFJqrpHRH4A3B716AY4f/sgvT1HxZi4NzQ9hfLR2ZSPzv7cupbWNrY17D8i2bQnn/c27WLP/iNHBLIzUijOy2RMnnfGVJznfY3J9dryMlMH7eSBsOfgqWpT0MsfYUmlW+3TiW3mlzEDW0pyEmPd5a9TJx25TlVp2HfwULLZsnsfW3btY8vufWyq38tbVXU0NbcesU9mWrJ3ia5DsinOG0Jx7hAKhqYP2MdB93Zi98B8t/3MF2gkJUkYn2+FJI0ZrESE3Mw0cjPTOGZs7ufWtyedml37qHHJxks6e6nZtY8PNu9m996DR+yTlpzEyJwMRuZkMDong5E5Qxh16PUQRuZkkJ+VFpeJp7dJJXHr5feAP9DEuOGZVm7CmAQWnHQ6VhZo13igha2791Gzay9bdu2jZvc+tjfsZ9vu/by7aRfbG7ZxsPXIX7upyUJR9uEk0550RrkENConIyZnPJ0mFRHZQ+jkIcCQqEU0iHiFJO3SlzGma0PTUw7d+BlKW5tS39TsJZqGfWz/bD9bd+9ne8O+Q8+/eXb1/kNlbtqlJHmJZ2ROBkXZ6d5ydgZF2RmcUprPiOyMkMfri06TiqqG/ZRH83lWSNIYEylJSeJK26RzdHHosx1VZWdTM9sa9rOt4XDC8Zb3s277Hl5dHzg0vvPwFbP6N6mYvmkvJGk3Phpj+oOIkD80nfyh6Z1eZgPYs/8gOz47wKicyCcUsKQSNYdrftl0YmNM/BiWkRrV+2iiOoIsInNEZL2IVInI9SHWp4vIYrd+uYiUBK27wbWvF5Hze9DnHSLSGK33FC6bTmyMSURRSyoikgzcCVwAlAMLRKS8w2ZXArtUdRJwG3Cr27ccmA9MB+YAd4lIcnd9ikgFkEcc8AWayLNCksaYBBPNM5VZQJWq+lW1GVgER1S0xr1+yC0vBWaLd5vpXGCRqh5Q1WqgyvXXaZ8u4fwKuC6K7ylsvoDN/DLGJJ5oJpUxwOag1zWuLeQ2qtqC9yCw/C727arPa4FlqtplsUsRuVpEKkWkMhAI9OgN9YQ/0ESpjacYYxLMoLgrT0RGA5fgPe64S6p6j6pWqGpFYWF0qge3F5K0MxVjTKKJZlLZAowNel3s2kJuIyIpQA5Q38W+nbUfC0wCqkRkI5ApIlWReiM9ZYUkjTGJKppJZSVQJiITRCQNb+B9WYdtlgGXu+V5wEuqqq59vpsdNgEoA1Z01qeq/k1VR6pqiaqWAHvd4H9M+NqfS28l740xCSZq96moaouIXAs8ByQDC1V1jYjcDFSq6jLgfuARd1axEy9J4LZbAqzFe8rkNaraChCqz2i9h97yu0KS44ZbIUljTGKJ6s2Pqvo08HSHthuDlvfjjYWE2vcW4JZw+gyxTUxPEfyBJsblWyFJY0zisd96UeALNDKxwC59GWMSjyWVCGtpbePT+r2UjrBBemNM4rGkEmE1u/Z5hSTtTMUYk4AsqUSYv84KSRpjEpcllQhrLyRpJe+NMYnIkkqE+QKN5GWmkmeFJI0xCciSSoT5Ak12lmKMSViWVCLMH2i08RRjTMKypBJBDXsPUtfYbIUkjTEJy5JKBPnczC+7/GWMSVSWVCLo8COE7fKXMSYxWVKJICskaYxJdJZUIsgXaLRCksaYhGa//SLIb9OJjTEJzpJKhLS0trGxvsnGU4wxCc2SSoTU7NrHwVa1QpLGmIRmSSVC2gtJWsl7Y0wis6QSIb5aN53YzlSMMQnMkkqE+OsaGZ6VZoUkjTEJLapJRUTmiMh6EakSketDrE8XkcVu/XIRKQlad4NrXy8i53fXp4g86tpXi8hCEUmN5nvryFfbxMQCu/RljElsUUsqIpIM3AlcAJQDC0SkvMNmVwK7VHUScBtwq9u3HJgPTAfmAHeJSHI3fT4KTAWOBoYA/xyt9xaKv84KSRpjTDTPVGYBVarqV9VmYBEwt8M2c4GH3PJSYLaIiGtfpKoHVLUaqHL9ddqnqj6tDrACKI7ieztCeyFJu0fFGJPooplUxgCbg17XuLaQ26hqC9AA5Hexb7d9uste/wQ82+d3ECbfoUcIW1IxxiS2wThQfxfwmqq+HmqliFwtIpUiUhkIBCJywMOPELbLX8aYxBbNpLIFGBv0uti1hdxGRFKAHKC+i3277FNE/gMoBH7UWVCqeo+qVqhqRWFhYQ/fUmg+V0hyrBWSNMYkuGgmlZVAmYhMEJE0vIH3ZR22WQZc7pbnAS+5MZFlwHw3O2wCUIY3TtJpnyLyz8D5wAJVbYvi+/ocf6CR8VZI0hhjSIlWx6raIiLXAs8BycBCVV0jIjcDlaq6DLgfeEREqoCdeEkCt90SYC3QAlyjqq0Aofp0h7wb+BR42xvr5wlVvTla7y+YL9Bk4ynGGEMUkwp4M7KApzu03Ri0vB+4pJN9bwFuCadP1x7V99KZltY2Pq1vYva0EbE4vDHGxBW7XtNHhwpJ2pmKMcZYUukrX6D9ufQ288sYYyyp9NGh59JbIUljjLGk0le+gBWSNMaYdpZU+sgfsEKSxhjTzpJKH/kCjTZIb4wxjiWVPmjYe5D6pmarTmyMMY4llT5oLyRpZyrGGOOxpNIHvtr26sR2pmKMMWBJpU/8dU2kJlshSWOMaWdJpQ98tY2MG26FJI0xpp39NuwDf50VkjTGmGCWVHqpvZCkDdIbY8xhllR6abMrJGmD9MYYc5gllV7yB2w6sTHGdGRJpZesOrExxnyeJZVe8geayM9KIzfTCkkaY0w7Syq95As02niKMcZ0YEmll7zqxDaeYowxwSyp9MLuvc3UNzVTOsLOVIwxJlhUk4qIzBGR9SJSJSLXh1ifLiKL3frlIlIStO4G175eRM7vrk8RmeD6qHJ9Rm2ww2dPezTGmJCillREJBm4E7gAKAcWiEh5h82uBHap6iTgNuBWt285MB+YDswB7hKR5G76vBW4zfW1y/UdFYemE4+wpGKMMcGieaYyC6hSVb+qNgOLgLkdtpkLPOSWlwKzRURc+yJVPaCq1UCV6y9kn26fs10fuD7/IVpvzBdwhSTzhkTrEMYYMyBFM6mMATYHva5xbSG3UdUWoAHI72Lfztrzgd2uj86OBYCIXC0ilSJSGQgEevG2oCQ/ky8fO4YUKyRpjDFHSLjfiqp6j6pWqGpFYWFhr/qYP2scv5x3TIQjM8aYgS+aSWULMDbodbFrC7mNiKQAOUB9F/t21l4P5Lo+OjuWMcaYKItmUlkJlLlZWWl4A+/LOmyzDLjcLc8DXlJVde3z3eywCUAZsKKzPt0+L7s+cH0+GcX3ZowxJoSU7jfpHVVtEZFrgeeAZGChqq4RkZuBSlVdBtwPPCIiVcBOvCSB224JsBZoAa5R1VaAUH26Q/4UWCQiPwfed30bY4zpR+L9kZ+YKioqtLKyMtZhGGPMgCIi76pqRah1CTdQb4wxJnosqRhjjIkYSyrGGGMixpKKMcaYiEnogXoRCQCf9nL3AqAuguFEisXVMxZXz1hcPROvcUHfYhuvqiHvHk/opNIXIlLZ2eyHWLK4esbi6hmLq2fiNS6IXmx2+csYY0zEWFIxxhgTMZZUeu+eWAfQCYurZyyunrG4eiZe44IoxWZjKsYYYyLGzlSMMcZEjCUVY4wxEWNJpRdEZI6IrBeRKhG5vh+Ot1FEPhKRD0Sk0rUNF5EXRGSD+57n2kVE7nCxfSgixwX1c7nbfoOIXN7Z8bqJZaGI1IrI6qC2iMUiIse791rl9pU+xHWTiGxxn9sHInJh0Lob3DHWi8j5Qe0hf7bucQvLXfti9+iF7mIaKyIvi8haEVkjIt+Ph8+ri7hi+nm5/TJEZIWIrHKx/WdX/Yn3eIzFrn25iJT0NuZexvWgiFQHfWYzXXt//ttPFpH3ReSv8fBZoar21YMvvJL7PmAikAasAsqjfMyNQEGHtl8C17vl64Fb3fKFwDOAACcBy137cMDvvue55bxexHIGcBywOhqx4D035yS3zzPABX2I6ybgJyG2LXc/t3Rggvt5Jnf1swWWAPPd8t3At8OIaRRwnFseBnzijh3Tz6uLuGL6ebltBRjqllOB5e79hewP+A5wt1ueDyzubcy9jOtBYF6I7fvz3/6PgMeAv3b12ffXZ2VnKj03C6hSVb+qNgOLgLkxiGMu8JBbfgj4h6D2h9XzDt4TMUcB5wMvqOpOVd0FvADM6elBVfU1vGffRDwWty5bVd9R71/7w0F99SauzswFFqnqAVWtBqrwfq4hf7buL8azgaUh3mNXMW1T1ffc8h7gY2AMMf68uoirM/3yebl4VFUb3ctU96Vd9Bf8WS4FZrvj9yjmPsTVmX75WYpIMXARcJ973dVn3y+flSWVnhsDbA56XUPX/yEjQYHnReRdEbnatRWp6ja3vB0o6ia+aMYdqVjGuOVIxnitu/ywUNxlpl7ElQ/sVtWW3sblLjUci/cXbtx8Xh3igjj4vNzlnA+AWrxfur4u+jsUg1vf4I4f8f8HHeNS1fbP7Bb3md0mIukd4wrz+L39Wd4OXAe0udddffb98llZUhkYTlPV44ALgGtE5Izgle4vm7iYGx5PsQB/AEqBmcA24L9jEYSIDAX+BPxAVT8LXhfLzytEXHHxealqq6rOBIrx/lqeGos4OuoYl4gcBdyAF98JeJe0ftpf8YjIF4FaVX23v44ZDksqPbcFGBv0uti1RY2qbnHfa4E/4/1H2+FOmXHfa7uJL5pxRyqWLW45IjGq6g73i6ANuBfvc+tNXPV4ly9SOrR3S0RS8X5xP6qqT7jmmH9eoeKKh88rmKruBl4GTu6iv0MxuPU57vhR+38QFNccdylRVfUA8AC9/8x687M8FbhYRDbiXZo6G/gtsf6suht0sa/PDYql4A2uTeDw4NX0KB4vCxgWtPwW3ljIrzhysPeXbvkijhwgXOHahwPVeIODeW55eC9jKuHIAfGIxcLnBysv7ENco4KWf4h33RhgOkcOTPrxBiU7/dkCf+TIwc/vhBGP4F0bv71De0w/ry7iiunn5bYtBHLd8hDgdeCLnfUHXMORg89LehtzL+MaFfSZ3g78Ikb/9s/i8EB9bD+r3vxSSfQvvJkdn+Bd6/1ZlI810f0wVwFr2o+Hdy3078AG4MWgf5gC3Oli+wioCOrrCrxBuCrgm72M53G8SyMH8a6xXhnJWIAKYLXb5/e4qg+9jOsRd9wPgWUc+UvzZ+4Y6wmaZdPZz9b9HFa4eP8IpIcR02l4l7Y+BD5wXxfG+vPqIq6Yfl5uvxnA+y6G1cCNXfUHZLjXVW79xN7G3Mu4XnKf2Wrgfzk8Q6zf/u27fc/icFKJ6WdlZVqMMcZEjI2pGGOMiRhLKsYYYyLGkooxxpiIsaRijDEmYiypGGOMiRhLKsb0kIjkB1Wl3S5HVvbtshqviFSIyB09PN4VrnrthyKyWkTmuvZviMjovrwXYyLNphQb0wcichPQqKq/DmpL0cO1l/rafzHwKl5V4QZXWqVQVatF5BW8qsKVkTiWMZFgZyrGRIB7rsbdIrIc+KWIzBKRt91zLt4SkSluu7OCnntxkyvc+IqI+EXkeyG6HgHsARoBVLXRJZR5eDfLPerOkIa453G86gqPPhdUCuYVEfmt2261iMwKcRxjIsKSijGRUwycoqo/AtYBp6vqscCNwH91ss9UvHLos4D/cDW5gq0CdgDVIvKAiHwJQFWXApXAZeoVOWwBfof3bI/jgYXALUH9ZLrtvuPWGRMVKd1vYowJ0x9VtdUt5wAPiUgZXkmUjsmi3d/UK0Z4QERq8crgHyqBrqqtIjIHrwrubOA2ETleVW/q0M8U4CjgBe8RGSTjla1p97jr7zURyRaRXPUKIxoTUZZUjImcpqDl/w94WVW/7J5Z8kon+xwIWm4lxP9J9QY+VwArROQFvGq4N3XYTIA1qnpyJ8fpOHhqg6kmKuzylzHRkcPhMuHf6G0nIjJagp5vjvesk0/d8h68xwGDVwiwUEROdvulisj0oP0ude2nAQ2q2tDbmIzpip2pGBMdv8S7/PVvwN/60E8q8Gs3dXg/EAC+5dY9CNwtIvvwnjkyD7hDRHLw/m/fjlfZGmC/iLzv+ruiD/EY0yWbUmzMIGdTj01/sstfxhhjIsbOVIwxxkSMnakYY4yJGEsqxhhjIsaSijHGmIixpGKMMSZiLKkYY4yJmP8HLnCrOoiHd3sAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zceUmkJI35zb"
      },
      "source": [
        "## Build model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qoczioW23-Da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "814e0135-5632-4fbc-f466-3903792122c4"
      },
      "source": [
        "_ = model(x_train)\n",
        "\n",
        "print(model.summary())"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"transformer_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "encoder_6 (Encoder)          multiple                  120448    \n",
            "_________________________________________________________________\n",
            "decoder_6 (Decoder)          multiple                  749824    \n",
            "_________________________________________________________________\n",
            "dense_370 (Dense)            multiple                  2322      \n",
            "=================================================================\n",
            "Total params: 872,594\n",
            "Trainable params: 872,594\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SunnK0BY2utQ"
      },
      "source": [
        "# Load model checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gi46si8f2bOi"
      },
      "source": [
        "checkpoint_file = os.path.join(checkpoint_dir, 'cp.ckpt')\n",
        "\n",
        "if os.path.isdir(checkpoint_dir) and os.listdir(checkpoint_dir):\n",
        "    model.load_weights(checkpoint_file)"
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkCyoCxp3l7r"
      },
      "source": [
        "## Create training callbacks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23w7DNkh2ytf"
      },
      "source": [
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_file,\n",
        "    save_weights_only=False,\n",
        "    verbose=0,\n",
        "    save_freq='epoch')\n",
        "\n",
        "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20)\n",
        "\n",
        "# def scheduler(epoch, lr):\n",
        "#   if epoch < 10:\n",
        "#     return lr\n",
        "#   else:\n",
        "#     return lr * 0.9\n",
        "\n",
        "# lr_scheduler = tf.keras.callbacks.LearningRateScheduler(scheduler)"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCkWXZD-5XsD"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xl4D5c_u5a1x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd793807-792f-4fc0-dfae-02f3b2f358cf"
      },
      "source": [
        "epochs = 500\n",
        "steps_per_epoch = 100\n",
        "validation_steps = 10\n",
        "\n",
        "model.fit(train_dataset,\n",
        "          epochs=epochs,\n",
        "          steps_per_epoch=steps_per_epoch,\n",
        "          validation_data=valid_dataset,\n",
        "          validation_steps=validation_steps,\n",
        "          callbacks=[checkpoint, early_stop])"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "100/100 [==============================] - 29s 232ms/step - loss: 1.6575 - mean_squared_error: 4.4737 - val_loss: 1.2040 - val_mean_squared_error: 2.5401\n",
            "Epoch 2/500\n",
            "100/100 [==============================] - 22s 222ms/step - loss: 1.2363 - mean_squared_error: 2.7127 - val_loss: 1.0593 - val_mean_squared_error: 2.0832\n",
            "Epoch 3/500\n",
            "100/100 [==============================] - 22s 222ms/step - loss: 1.0902 - mean_squared_error: 2.1841 - val_loss: 0.7814 - val_mean_squared_error: 1.1600\n",
            "Epoch 4/500\n",
            "100/100 [==============================] - 22s 223ms/step - loss: 0.8260 - mean_squared_error: 1.2647 - val_loss: 0.5571 - val_mean_squared_error: 0.5973\n",
            "Epoch 5/500\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.6514 - mean_squared_error: 0.7811 - val_loss: 0.4191 - val_mean_squared_error: 0.3461\n",
            "Epoch 6/500\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.5294 - mean_squared_error: 0.5191 - val_loss: 0.3311 - val_mean_squared_error: 0.2166\n",
            "Epoch 7/500\n",
            "100/100 [==============================] - 22s 223ms/step - loss: 0.4505 - mean_squared_error: 0.3708 - val_loss: 0.2805 - val_mean_squared_error: 0.1552\n",
            "Epoch 8/500\n",
            "100/100 [==============================] - 22s 223ms/step - loss: 0.3964 - mean_squared_error: 0.2885 - val_loss: 0.2511 - val_mean_squared_error: 0.1231\n",
            "Epoch 9/500\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.3560 - mean_squared_error: 0.2327 - val_loss: 0.2273 - val_mean_squared_error: 0.0997\n",
            "Epoch 10/500\n",
            "100/100 [==============================] - 22s 223ms/step - loss: 0.3241 - mean_squared_error: 0.1927 - val_loss: 0.2159 - val_mean_squared_error: 0.0894\n",
            "Epoch 11/500\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.2977 - mean_squared_error: 0.1635 - val_loss: 0.1968 - val_mean_squared_error: 0.0748\n",
            "Epoch 12/500\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.2806 - mean_squared_error: 0.1464 - val_loss: 0.1864 - val_mean_squared_error: 0.0673\n",
            "Epoch 13/500\n",
            "100/100 [==============================] - 22s 225ms/step - loss: 0.2642 - mean_squared_error: 0.1310 - val_loss: 0.1722 - val_mean_squared_error: 0.0580\n",
            "Epoch 14/500\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.2488 - mean_squared_error: 0.1160 - val_loss: 0.1730 - val_mean_squared_error: 0.0579\n",
            "Epoch 15/500\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.2382 - mean_squared_error: 0.1067 - val_loss: 0.1593 - val_mean_squared_error: 0.0501\n",
            "Epoch 16/500\n",
            "100/100 [==============================] - 22s 225ms/step - loss: 0.2287 - mean_squared_error: 0.0995 - val_loss: 0.1578 - val_mean_squared_error: 0.0492\n",
            "Epoch 17/500\n",
            "100/100 [==============================] - 22s 225ms/step - loss: 0.2235 - mean_squared_error: 0.0956 - val_loss: 0.1479 - val_mean_squared_error: 0.0432\n",
            "Epoch 18/500\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.2119 - mean_squared_error: 0.0864 - val_loss: 0.1604 - val_mean_squared_error: 0.0505\n",
            "Epoch 19/500\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.2049 - mean_squared_error: 0.0804 - val_loss: 0.1572 - val_mean_squared_error: 0.0459\n",
            "Epoch 20/500\n",
            "100/100 [==============================] - 23s 225ms/step - loss: 0.1971 - mean_squared_error: 0.0743 - val_loss: 0.1428 - val_mean_squared_error: 0.0413\n",
            "Epoch 21/500\n",
            "100/100 [==============================] - 22s 225ms/step - loss: 0.1933 - mean_squared_error: 0.0717 - val_loss: 0.1465 - val_mean_squared_error: 0.0417\n",
            "Epoch 22/500\n",
            "100/100 [==============================] - 22s 225ms/step - loss: 0.1860 - mean_squared_error: 0.0668 - val_loss: 0.1331 - val_mean_squared_error: 0.0341\n",
            "Epoch 23/500\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.1806 - mean_squared_error: 0.0629 - val_loss: 0.1355 - val_mean_squared_error: 0.0340\n",
            "Epoch 24/500\n",
            "100/100 [==============================] - 22s 223ms/step - loss: 0.1741 - mean_squared_error: 0.0583 - val_loss: 0.1277 - val_mean_squared_error: 0.0320\n",
            "Epoch 25/500\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.1719 - mean_squared_error: 0.0565 - val_loss: 0.1210 - val_mean_squared_error: 0.0282\n",
            "Epoch 26/500\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.1650 - mean_squared_error: 0.0528 - val_loss: 0.1187 - val_mean_squared_error: 0.0277\n",
            "Epoch 27/500\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.1641 - mean_squared_error: 0.0519 - val_loss: 0.1080 - val_mean_squared_error: 0.0225\n",
            "Epoch 28/500\n",
            "100/100 [==============================] - 22s 225ms/step - loss: 0.1548 - mean_squared_error: 0.0464 - val_loss: 0.1130 - val_mean_squared_error: 0.0243\n",
            "Epoch 29/500\n",
            "100/100 [==============================] - 22s 223ms/step - loss: 0.1510 - mean_squared_error: 0.0433 - val_loss: 0.1077 - val_mean_squared_error: 0.0216\n",
            "Epoch 30/500\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.1478 - mean_squared_error: 0.0422 - val_loss: 0.0954 - val_mean_squared_error: 0.0176\n",
            "Epoch 31/500\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.1429 - mean_squared_error: 0.0394 - val_loss: 0.0951 - val_mean_squared_error: 0.0173\n",
            "Epoch 32/500\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.1355 - mean_squared_error: 0.0348 - val_loss: 0.0871 - val_mean_squared_error: 0.0144\n",
            "Epoch 33/500\n",
            "100/100 [==============================] - 22s 223ms/step - loss: 0.1333 - mean_squared_error: 0.0342 - val_loss: 0.0938 - val_mean_squared_error: 0.0166\n",
            "Epoch 34/500\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.1330 - mean_squared_error: 0.0342 - val_loss: 0.0945 - val_mean_squared_error: 0.0165\n",
            "Epoch 35/500\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.1292 - mean_squared_error: 0.0318 - val_loss: 0.0856 - val_mean_squared_error: 0.0144\n",
            "Epoch 36/500\n",
            "100/100 [==============================] - 22s 225ms/step - loss: 0.1273 - mean_squared_error: 0.0308 - val_loss: 0.0868 - val_mean_squared_error: 0.0136\n",
            "Epoch 37/500\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.1218 - mean_squared_error: 0.0284 - val_loss: 0.0801 - val_mean_squared_error: 0.0118\n",
            "Epoch 38/500\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.1193 - mean_squared_error: 0.0273 - val_loss: 0.0781 - val_mean_squared_error: 0.0113\n",
            "Epoch 39/500\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.1178 - mean_squared_error: 0.0268 - val_loss: 0.0759 - val_mean_squared_error: 0.0107\n",
            "Epoch 40/500\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.1145 - mean_squared_error: 0.0252 - val_loss: 0.0921 - val_mean_squared_error: 0.0153\n",
            "Epoch 41/500\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.1157 - mean_squared_error: 0.0258 - val_loss: 0.0723 - val_mean_squared_error: 0.0103\n",
            "Epoch 42/500\n",
            "100/100 [==============================] - 22s 223ms/step - loss: 0.1152 - mean_squared_error: 0.0256 - val_loss: 0.0640 - val_mean_squared_error: 0.0078\n",
            "Epoch 43/500\n",
            "100/100 [==============================] - 22s 223ms/step - loss: 0.1081 - mean_squared_error: 0.0225 - val_loss: 0.0614 - val_mean_squared_error: 0.0071\n",
            "Epoch 44/500\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.1076 - mean_squared_error: 0.0222 - val_loss: 0.0604 - val_mean_squared_error: 0.0070\n",
            "Epoch 45/500\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.1032 - mean_squared_error: 0.0206 - val_loss: 0.0660 - val_mean_squared_error: 0.0078\n",
            "Epoch 46/500\n",
            "100/100 [==============================] - 22s 225ms/step - loss: 0.1002 - mean_squared_error: 0.0196 - val_loss: 0.0637 - val_mean_squared_error: 0.0076\n",
            "Epoch 47/500\n",
            "100/100 [==============================] - 22s 225ms/step - loss: 0.0962 - mean_squared_error: 0.0181 - val_loss: 0.0534 - val_mean_squared_error: 0.0055\n",
            "Epoch 48/500\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.0939 - mean_squared_error: 0.0173 - val_loss: 0.0493 - val_mean_squared_error: 0.0047\n",
            "Epoch 49/500\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.0889 - mean_squared_error: 0.0156 - val_loss: 0.0544 - val_mean_squared_error: 0.0058\n",
            "Epoch 50/500\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.0876 - mean_squared_error: 0.0153 - val_loss: 0.0583 - val_mean_squared_error: 0.0065\n",
            "Epoch 51/500\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.0819 - mean_squared_error: 0.0132 - val_loss: 0.0457 - val_mean_squared_error: 0.0040\n",
            "Epoch 52/500\n",
            "100/100 [==============================] - 22s 225ms/step - loss: 0.0793 - mean_squared_error: 0.0128 - val_loss: 0.0496 - val_mean_squared_error: 0.0046\n",
            "Epoch 53/500\n",
            "100/100 [==============================] - 22s 225ms/step - loss: 0.0765 - mean_squared_error: 0.0116 - val_loss: 0.0453 - val_mean_squared_error: 0.0037\n",
            "Epoch 54/500\n",
            "100/100 [==============================] - 22s 225ms/step - loss: 0.0728 - mean_squared_error: 0.0107 - val_loss: 0.0443 - val_mean_squared_error: 0.0038\n",
            "Epoch 55/500\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.0712 - mean_squared_error: 0.0103 - val_loss: 0.0373 - val_mean_squared_error: 0.0025\n",
            "Epoch 56/500\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.0685 - mean_squared_error: 0.0095 - val_loss: 0.0373 - val_mean_squared_error: 0.0028\n",
            "Epoch 57/500\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.0642 - mean_squared_error: 0.0085 - val_loss: 0.0366 - val_mean_squared_error: 0.0027\n",
            "Epoch 58/500\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.0664 - mean_squared_error: 0.0091 - val_loss: 0.0319 - val_mean_squared_error: 0.0020\n",
            "Epoch 59/500\n",
            "100/100 [==============================] - 22s 225ms/step - loss: 0.0599 - mean_squared_error: 0.0072 - val_loss: 0.0295 - val_mean_squared_error: 0.0017\n",
            "Epoch 60/500\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.0581 - mean_squared_error: 0.0070 - val_loss: 0.0351 - val_mean_squared_error: 0.0024\n",
            "Epoch 61/500\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.0573 - mean_squared_error: 0.0067 - val_loss: 0.0283 - val_mean_squared_error: 0.0016\n",
            "Epoch 62/500\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.0557 - mean_squared_error: 0.0063 - val_loss: 0.0308 - val_mean_squared_error: 0.0019\n",
            "Epoch 63/500\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.0538 - mean_squared_error: 0.0060 - val_loss: 0.0270 - val_mean_squared_error: 0.0014\n",
            "Epoch 64/500\n",
            "100/100 [==============================] - 22s 223ms/step - loss: 0.0529 - mean_squared_error: 0.0057 - val_loss: 0.0261 - val_mean_squared_error: 0.0013\n",
            "Epoch 65/500\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.0519 - mean_squared_error: 0.0058 - val_loss: 0.0242 - val_mean_squared_error: 0.0012\n",
            "Epoch 66/500\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.0494 - mean_squared_error: 0.0052 - val_loss: 0.0282 - val_mean_squared_error: 0.0015\n",
            "Epoch 67/500\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.0505 - mean_squared_error: 0.0054 - val_loss: 0.0283 - val_mean_squared_error: 0.0015\n",
            "Epoch 68/500\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.0485 - mean_squared_error: 0.0049 - val_loss: 0.0266 - val_mean_squared_error: 0.0013\n",
            "Epoch 69/500\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.0477 - mean_squared_error: 0.0048 - val_loss: 0.0242 - val_mean_squared_error: 0.0011\n",
            "Epoch 70/500\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.0458 - mean_squared_error: 0.0044 - val_loss: 0.0323 - val_mean_squared_error: 0.0020\n",
            "Epoch 71/500\n",
            "100/100 [==============================] - 22s 225ms/step - loss: 0.0475 - mean_squared_error: 0.0048 - val_loss: 0.0246 - val_mean_squared_error: 0.0012\n",
            "Epoch 72/500\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.0442 - mean_squared_error: 0.0041 - val_loss: 0.0199 - val_mean_squared_error: 7.5754e-04\n",
            "Epoch 73/500\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.0428 - mean_squared_error: 0.0039 - val_loss: 0.0227 - val_mean_squared_error: 9.5449e-04\n",
            "Epoch 74/500\n",
            "100/100 [==============================] - 22s 223ms/step - loss: 0.0430 - mean_squared_error: 0.0039 - val_loss: 0.0238 - val_mean_squared_error: 0.0011\n",
            "Epoch 75/500\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.0431 - mean_squared_error: 0.0039 - val_loss: 0.0234 - val_mean_squared_error: 0.0011\n",
            "Epoch 76/500\n",
            "100/100 [==============================] - 22s 223ms/step - loss: 0.0416 - mean_squared_error: 0.0037 - val_loss: 0.0228 - val_mean_squared_error: 9.6801e-04\n",
            "Epoch 77/500\n",
            "100/100 [==============================] - 22s 225ms/step - loss: 0.0409 - mean_squared_error: 0.0035 - val_loss: 0.0243 - val_mean_squared_error: 0.0011\n",
            "Epoch 78/500\n",
            "100/100 [==============================] - 22s 225ms/step - loss: 0.0411 - mean_squared_error: 0.0036 - val_loss: 0.0219 - val_mean_squared_error: 9.8060e-04\n",
            "Epoch 79/500\n",
            "100/100 [==============================] - 22s 225ms/step - loss: 0.0395 - mean_squared_error: 0.0033 - val_loss: 0.0225 - val_mean_squared_error: 9.0637e-04\n",
            "Epoch 80/500\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.0395 - mean_squared_error: 0.0034 - val_loss: 0.0224 - val_mean_squared_error: 9.3284e-04\n",
            "Epoch 81/500\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.0385 - mean_squared_error: 0.0032 - val_loss: 0.0221 - val_mean_squared_error: 8.9253e-04\n",
            "Epoch 82/500\n",
            "100/100 [==============================] - 22s 225ms/step - loss: 0.0378 - mean_squared_error: 0.0031 - val_loss: 0.0212 - val_mean_squared_error: 8.5846e-04\n",
            "Epoch 83/500\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.0372 - mean_squared_error: 0.0030 - val_loss: 0.0204 - val_mean_squared_error: 7.9426e-04\n",
            "Epoch 84/500\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.0374 - mean_squared_error: 0.0031 - val_loss: 0.0186 - val_mean_squared_error: 6.6700e-04\n",
            "Epoch 85/500\n",
            "100/100 [==============================] - 22s 225ms/step - loss: 0.0363 - mean_squared_error: 0.0028 - val_loss: 0.0179 - val_mean_squared_error: 6.2721e-04\n",
            "Epoch 86/500\n",
            "100/100 [==============================] - 23s 225ms/step - loss: 0.0355 - mean_squared_error: 0.0027 - val_loss: 0.0182 - val_mean_squared_error: 6.4829e-04\n",
            "Epoch 87/500\n",
            "100/100 [==============================] - 22s 225ms/step - loss: 0.0372 - mean_squared_error: 0.0030 - val_loss: 0.0153 - val_mean_squared_error: 4.4628e-04\n",
            "Epoch 88/500\n",
            "100/100 [==============================] - 22s 225ms/step - loss: 0.0347 - mean_squared_error: 0.0026 - val_loss: 0.0235 - val_mean_squared_error: 0.0010\n",
            "Epoch 89/500\n",
            "100/100 [==============================] - 22s 225ms/step - loss: 0.0362 - mean_squared_error: 0.0028 - val_loss: 0.0169 - val_mean_squared_error: 5.1302e-04\n",
            "Epoch 90/500\n",
            "100/100 [==============================] - 23s 225ms/step - loss: 0.0347 - mean_squared_error: 0.0026 - val_loss: 0.0194 - val_mean_squared_error: 6.9423e-04\n",
            "Epoch 91/500\n",
            "100/100 [==============================] - 22s 225ms/step - loss: 0.0344 - mean_squared_error: 0.0026 - val_loss: 0.0154 - val_mean_squared_error: 4.3586e-04\n",
            "Epoch 92/500\n",
            "100/100 [==============================] - 22s 225ms/step - loss: 0.0333 - mean_squared_error: 0.0024 - val_loss: 0.0142 - val_mean_squared_error: 3.9045e-04\n",
            "Epoch 93/500\n",
            "100/100 [==============================] - 22s 225ms/step - loss: 0.0331 - mean_squared_error: 0.0024 - val_loss: 0.0189 - val_mean_squared_error: 6.6563e-04\n",
            "Epoch 94/500\n",
            "100/100 [==============================] - 22s 225ms/step - loss: 0.0336 - mean_squared_error: 0.0025 - val_loss: 0.0161 - val_mean_squared_error: 4.5114e-04\n",
            "Epoch 95/500\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.0324 - mean_squared_error: 0.0023 - val_loss: 0.0173 - val_mean_squared_error: 5.3875e-04\n",
            "Epoch 96/500\n",
            "100/100 [==============================] - 22s 223ms/step - loss: 0.0324 - mean_squared_error: 0.0023 - val_loss: 0.0181 - val_mean_squared_error: 6.1287e-04\n",
            "Epoch 97/500\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.0325 - mean_squared_error: 0.0023 - val_loss: 0.0152 - val_mean_squared_error: 4.4256e-04\n",
            "Epoch 98/500\n",
            "100/100 [==============================] - 22s 225ms/step - loss: 0.0318 - mean_squared_error: 0.0023 - val_loss: 0.0186 - val_mean_squared_error: 7.1897e-04\n",
            "Epoch 99/500\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.0317 - mean_squared_error: 0.0022 - val_loss: 0.0177 - val_mean_squared_error: 5.8998e-04\n",
            "Epoch 100/500\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.0326 - mean_squared_error: 0.0023 - val_loss: 0.0152 - val_mean_squared_error: 4.2178e-04\n",
            "Epoch 101/500\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.0308 - mean_squared_error: 0.0021 - val_loss: 0.0136 - val_mean_squared_error: 3.5195e-04\n",
            "Epoch 102/500\n",
            "100/100 [==============================] - 22s 223ms/step - loss: 0.0306 - mean_squared_error: 0.0021 - val_loss: 0.0133 - val_mean_squared_error: 3.3929e-04\n",
            "Epoch 103/500\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.0298 - mean_squared_error: 0.0020 - val_loss: 0.0139 - val_mean_squared_error: 3.7138e-04\n",
            "Epoch 104/500\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.0296 - mean_squared_error: 0.0020 - val_loss: 0.0149 - val_mean_squared_error: 3.9472e-04\n",
            "Epoch 105/500\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.0309 - mean_squared_error: 0.0021 - val_loss: 0.0155 - val_mean_squared_error: 4.3596e-04\n",
            "Epoch 106/500\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.0294 - mean_squared_error: 0.0020 - val_loss: 0.0157 - val_mean_squared_error: 4.6214e-04\n",
            "Epoch 107/500\n",
            "100/100 [==============================] - 22s 223ms/step - loss: 0.0297 - mean_squared_error: 0.0020 - val_loss: 0.0141 - val_mean_squared_error: 4.2328e-04\n",
            "Epoch 108/500\n",
            "100/100 [==============================] - 22s 223ms/step - loss: 0.0288 - mean_squared_error: 0.0019 - val_loss: 0.0152 - val_mean_squared_error: 4.2693e-04\n",
            "Epoch 109/500\n",
            "100/100 [==============================] - 22s 223ms/step - loss: 0.0282 - mean_squared_error: 0.0018 - val_loss: 0.0148 - val_mean_squared_error: 3.9675e-04\n",
            "Epoch 110/500\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.0297 - mean_squared_error: 0.0020 - val_loss: 0.0157 - val_mean_squared_error: 4.7051e-04\n",
            "Epoch 111/500\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.0295 - mean_squared_error: 0.0019 - val_loss: 0.0152 - val_mean_squared_error: 4.2628e-04\n",
            "Epoch 112/500\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.0293 - mean_squared_error: 0.0019 - val_loss: 0.0158 - val_mean_squared_error: 4.5658e-04\n",
            "Epoch 113/500\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.0278 - mean_squared_error: 0.0017 - val_loss: 0.0169 - val_mean_squared_error: 5.1238e-04\n",
            "Epoch 114/500\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.0289 - mean_squared_error: 0.0019 - val_loss: 0.0152 - val_mean_squared_error: 4.4189e-04\n",
            "Epoch 115/500\n",
            "100/100 [==============================] - 22s 223ms/step - loss: 0.0278 - mean_squared_error: 0.0018 - val_loss: 0.0138 - val_mean_squared_error: 3.5055e-04\n",
            "Epoch 116/500\n",
            "100/100 [==============================] - 22s 223ms/step - loss: 0.0278 - mean_squared_error: 0.0017 - val_loss: 0.0149 - val_mean_squared_error: 4.2118e-04\n",
            "Epoch 117/500\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.0273 - mean_squared_error: 0.0017 - val_loss: 0.0126 - val_mean_squared_error: 2.7968e-04\n",
            "Epoch 118/500\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.0275 - mean_squared_error: 0.0017 - val_loss: 0.0152 - val_mean_squared_error: 3.9704e-04\n",
            "Epoch 119/500\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.0269 - mean_squared_error: 0.0016 - val_loss: 0.0132 - val_mean_squared_error: 3.0976e-04\n",
            "Epoch 120/500\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.0266 - mean_squared_error: 0.0016 - val_loss: 0.0121 - val_mean_squared_error: 2.6862e-04\n",
            "Epoch 121/500\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.0263 - mean_squared_error: 0.0016 - val_loss: 0.0137 - val_mean_squared_error: 3.4067e-04\n",
            "Epoch 122/500\n",
            "100/100 [==============================] - 22s 225ms/step - loss: 0.0269 - mean_squared_error: 0.0016 - val_loss: 0.0111 - val_mean_squared_error: 2.4265e-04\n",
            "Epoch 123/500\n",
            "100/100 [==============================] - 22s 225ms/step - loss: 0.0258 - mean_squared_error: 0.0015 - val_loss: 0.0146 - val_mean_squared_error: 4.1045e-04\n",
            "Epoch 124/500\n",
            "100/100 [==============================] - 22s 225ms/step - loss: 0.0263 - mean_squared_error: 0.0015 - val_loss: 0.0130 - val_mean_squared_error: 3.1889e-04\n",
            "Epoch 125/500\n",
            "100/100 [==============================] - 22s 225ms/step - loss: 0.0256 - mean_squared_error: 0.0015 - val_loss: 0.0131 - val_mean_squared_error: 3.1741e-04\n",
            "Epoch 126/500\n",
            "100/100 [==============================] - 23s 225ms/step - loss: 0.0262 - mean_squared_error: 0.0015 - val_loss: 0.0129 - val_mean_squared_error: 3.2400e-04\n",
            "Epoch 127/500\n",
            "100/100 [==============================] - 22s 225ms/step - loss: 0.0258 - mean_squared_error: 0.0015 - val_loss: 0.0125 - val_mean_squared_error: 2.7921e-04\n",
            "Epoch 128/500\n",
            "100/100 [==============================] - 22s 225ms/step - loss: 0.0256 - mean_squared_error: 0.0015 - val_loss: 0.0148 - val_mean_squared_error: 4.0903e-04\n",
            "Epoch 129/500\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.0256 - mean_squared_error: 0.0015 - val_loss: 0.0130 - val_mean_squared_error: 3.1715e-04\n",
            "Epoch 130/500\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.0249 - mean_squared_error: 0.0014 - val_loss: 0.0137 - val_mean_squared_error: 3.7045e-04\n",
            "Epoch 131/500\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.0253 - mean_squared_error: 0.0014 - val_loss: 0.0115 - val_mean_squared_error: 2.3376e-04\n",
            "Epoch 132/500\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.0253 - mean_squared_error: 0.0015 - val_loss: 0.0154 - val_mean_squared_error: 4.6154e-04\n",
            "Epoch 133/500\n",
            "100/100 [==============================] - 22s 225ms/step - loss: 0.0245 - mean_squared_error: 0.0014 - val_loss: 0.0116 - val_mean_squared_error: 2.4539e-04\n",
            "Epoch 134/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0244 - mean_squared_error: 0.0014 - val_loss: 0.0124 - val_mean_squared_error: 2.7974e-04\n",
            "Epoch 135/500\n",
            "100/100 [==============================] - 22s 225ms/step - loss: 0.0244 - mean_squared_error: 0.0014 - val_loss: 0.0120 - val_mean_squared_error: 2.7141e-04\n",
            "Epoch 136/500\n",
            "100/100 [==============================] - 22s 225ms/step - loss: 0.0243 - mean_squared_error: 0.0013 - val_loss: 0.0118 - val_mean_squared_error: 2.4352e-04\n",
            "Epoch 137/500\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.0239 - mean_squared_error: 0.0013 - val_loss: 0.0148 - val_mean_squared_error: 4.2074e-04\n",
            "Epoch 138/500\n",
            "100/100 [==============================] - 22s 225ms/step - loss: 0.0246 - mean_squared_error: 0.0014 - val_loss: 0.0121 - val_mean_squared_error: 2.8907e-04\n",
            "Epoch 139/500\n",
            "100/100 [==============================] - 22s 225ms/step - loss: 0.0242 - mean_squared_error: 0.0013 - val_loss: 0.0122 - val_mean_squared_error: 2.9813e-04\n",
            "Epoch 140/500\n",
            "100/100 [==============================] - 22s 225ms/step - loss: 0.0241 - mean_squared_error: 0.0013 - val_loss: 0.0109 - val_mean_squared_error: 2.1421e-04\n",
            "Epoch 141/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0236 - mean_squared_error: 0.0013 - val_loss: 0.0124 - val_mean_squared_error: 2.9644e-04\n",
            "Epoch 142/500\n",
            "100/100 [==============================] - 22s 225ms/step - loss: 0.0238 - mean_squared_error: 0.0013 - val_loss: 0.0107 - val_mean_squared_error: 2.0803e-04\n",
            "Epoch 143/500\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.0231 - mean_squared_error: 0.0012 - val_loss: 0.0124 - val_mean_squared_error: 2.8092e-04\n",
            "Epoch 144/500\n",
            "100/100 [==============================] - 22s 225ms/step - loss: 0.0232 - mean_squared_error: 0.0012 - val_loss: 0.0119 - val_mean_squared_error: 2.4840e-04\n",
            "Epoch 145/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0227 - mean_squared_error: 0.0012 - val_loss: 0.0123 - val_mean_squared_error: 2.7401e-04\n",
            "Epoch 146/500\n",
            "100/100 [==============================] - 22s 225ms/step - loss: 0.0242 - mean_squared_error: 0.0013 - val_loss: 0.0134 - val_mean_squared_error: 3.5332e-04\n",
            "Epoch 147/500\n",
            "100/100 [==============================] - 22s 225ms/step - loss: 0.0231 - mean_squared_error: 0.0012 - val_loss: 0.0119 - val_mean_squared_error: 2.4677e-04\n",
            "Epoch 148/500\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.0233 - mean_squared_error: 0.0012 - val_loss: 0.0098 - val_mean_squared_error: 1.7823e-04\n",
            "Epoch 149/500\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.0226 - mean_squared_error: 0.0012 - val_loss: 0.0115 - val_mean_squared_error: 2.5221e-04\n",
            "Epoch 150/500\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.0232 - mean_squared_error: 0.0012 - val_loss: 0.0136 - val_mean_squared_error: 3.5405e-04\n",
            "Epoch 151/500\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.0230 - mean_squared_error: 0.0012 - val_loss: 0.0104 - val_mean_squared_error: 1.8958e-04\n",
            "Epoch 152/500\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.0229 - mean_squared_error: 0.0012 - val_loss: 0.0111 - val_mean_squared_error: 2.2099e-04\n",
            "Epoch 153/500\n",
            "100/100 [==============================] - 22s 225ms/step - loss: 0.0224 - mean_squared_error: 0.0012 - val_loss: 0.0102 - val_mean_squared_error: 1.8188e-04\n",
            "Epoch 154/500\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.0219 - mean_squared_error: 0.0011 - val_loss: 0.0095 - val_mean_squared_error: 1.6733e-04\n",
            "Epoch 155/500\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.0217 - mean_squared_error: 0.0011 - val_loss: 0.0090 - val_mean_squared_error: 1.5275e-04\n",
            "Epoch 156/500\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.0220 - mean_squared_error: 0.0011 - val_loss: 0.0103 - val_mean_squared_error: 2.0842e-04\n",
            "Epoch 157/500\n",
            "100/100 [==============================] - 22s 223ms/step - loss: 0.0219 - mean_squared_error: 0.0011 - val_loss: 0.0139 - val_mean_squared_error: 3.8169e-04\n",
            "Epoch 158/500\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.0227 - mean_squared_error: 0.0012 - val_loss: 0.0101 - val_mean_squared_error: 1.8342e-04\n",
            "Epoch 159/500\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.0223 - mean_squared_error: 0.0011 - val_loss: 0.0104 - val_mean_squared_error: 2.0021e-04\n",
            "Epoch 160/500\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.0216 - mean_squared_error: 0.0011 - val_loss: 0.0099 - val_mean_squared_error: 1.7564e-04\n",
            "Epoch 161/500\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.0213 - mean_squared_error: 0.0011 - val_loss: 0.0112 - val_mean_squared_error: 2.1875e-04\n",
            "Epoch 162/500\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.0221 - mean_squared_error: 0.0011 - val_loss: 0.0115 - val_mean_squared_error: 2.5055e-04\n",
            "Epoch 163/500\n",
            "100/100 [==============================] - 22s 223ms/step - loss: 0.0225 - mean_squared_error: 0.0011 - val_loss: 0.0101 - val_mean_squared_error: 1.9051e-04\n",
            "Epoch 164/500\n",
            "100/100 [==============================] - 22s 223ms/step - loss: 0.0218 - mean_squared_error: 0.0011 - val_loss: 0.0108 - val_mean_squared_error: 2.1094e-04\n",
            "Epoch 165/500\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.0214 - mean_squared_error: 0.0011 - val_loss: 0.0092 - val_mean_squared_error: 1.4769e-04\n",
            "Epoch 166/500\n",
            "100/100 [==============================] - 22s 223ms/step - loss: 0.0211 - mean_squared_error: 0.0010 - val_loss: 0.0097 - val_mean_squared_error: 1.7370e-04\n",
            "Epoch 167/500\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.0209 - mean_squared_error: 0.0010 - val_loss: 0.0097 - val_mean_squared_error: 1.6961e-04\n",
            "Epoch 168/500\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.0210 - mean_squared_error: 0.0010 - val_loss: 0.0120 - val_mean_squared_error: 2.5432e-04\n",
            "Epoch 169/500\n",
            "100/100 [==============================] - 22s 223ms/step - loss: 0.0210 - mean_squared_error: 0.0010 - val_loss: 0.0105 - val_mean_squared_error: 2.0438e-04\n",
            "Epoch 170/500\n",
            "100/100 [==============================] - 22s 223ms/step - loss: 0.0214 - mean_squared_error: 0.0011 - val_loss: 0.0104 - val_mean_squared_error: 1.9635e-04\n",
            "Epoch 171/500\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.0211 - mean_squared_error: 0.0010 - val_loss: 0.0091 - val_mean_squared_error: 1.4692e-04\n",
            "Epoch 172/500\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.0205 - mean_squared_error: 9.9680e-04 - val_loss: 0.0129 - val_mean_squared_error: 3.0076e-04\n",
            "Epoch 173/500\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.0214 - mean_squared_error: 0.0011 - val_loss: 0.0108 - val_mean_squared_error: 2.2220e-04\n",
            "Epoch 174/500\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.0207 - mean_squared_error: 0.0010 - val_loss: 0.0118 - val_mean_squared_error: 2.7352e-04\n",
            "Epoch 175/500\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.0212 - mean_squared_error: 0.0010 - val_loss: 0.0112 - val_mean_squared_error: 2.5250e-04\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb9af1b32d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNyLeJcN6wS8"
      },
      "source": [
        "## Evaluate model on test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hX4SXagL6vwB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56fc6d6d-a1b5-41cd-aacf-a29408486a7f"
      },
      "source": [
        "model.evaluate(test_dataset, steps=500)"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "500/500 [==============================] - 46s 91ms/step - loss: 0.0112 - mean_squared_error: 2.5211e-04\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.011236613616347313, 0.0002521089627407491]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    }
  ]
}