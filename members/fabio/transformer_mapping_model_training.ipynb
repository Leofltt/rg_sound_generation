{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "transformer_mapping_model_training.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PcAvS4amzDrZ"
      },
      "source": [
        "# Mapping model training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0fVn8yUJl_v"
      },
      "source": [
        "## Setup Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m33xuTjEKazJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ad62a06-b820-4293-cc84-051b133e8c11"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vn7CQ4GQizHy"
      },
      "source": [
        "## Install Dependencies\n",
        "\n",
        "First we install the required dependencies with `pip`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjhdKFJbvRVU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dda2dc01-9ff4-414f-cb14-d649409b8491"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "!pip install -qU ddsp[data_preparation]==1.0.1"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |██                              | 10kB 21.5MB/s eta 0:00:01\r\u001b[K     |███▉                            | 20kB 20.1MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 30kB 15.3MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 40kB 13.6MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 51kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 61kB 7.6MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 71kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 81kB 9.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 92kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 102kB 7.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 112kB 7.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 122kB 7.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 133kB 7.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 143kB 7.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 153kB 7.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 163kB 7.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 174kB 7.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 92kB 7.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.6MB 13.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 215kB 34.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.8MB 45.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 9.0MB 55.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 20.2MB 1.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 5.6MB 22.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 378kB 42.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 61kB 7.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.2MB 51.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 17.7MB 145kB/s \n",
            "\u001b[K     |████████████████████████████████| 61kB 8.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 112kB 60.1MB/s \n",
            "\u001b[?25h  Building wheel for mir-eval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for cloudml-hypertune (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for crepe (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for avro-python3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pretty-midi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: apache-beam 2.28.0 has requirement avro-python3!=1.9.2,<1.10.0,>=1.8.1, but you'll have avro-python3 1.10.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: apache-beam 2.28.0 has requirement dill<0.3.2,>=0.3.1.1, but you'll have dill 0.3.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: apache-beam 2.28.0 has requirement future<1.0.0,>=0.18.2, but you'll have future 0.16.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: apache-beam 2.28.0 has requirement requests<3.0.0,>=2.24.0, but you'll have requests 2.23.0 which is incompatible.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LVV4Dc61HHY"
      },
      "source": [
        "## Make directories to save model and data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9XJcymGj1IwY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b53941ac-024e-45ca-8236-e12af28cd731"
      },
      "source": [
        "import os\n",
        "\n",
        "drive_dir = '/content/drive/My Drive/nsynth_guitar'\n",
        "checkpoint_dir = os.path.join(drive_dir, 'mapping/checkpoint')\n",
        "\n",
        "assert os.path.exists(drive_dir)\n",
        "print('Drive Directory Exists:', drive_dir)\n",
        "\n",
        "!mkdir -p \"$checkpoint_dir\""
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive Directory Exists: /content/drive/My Drive/nsynth_guitar\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fgGZzyMGyA4"
      },
      "source": [
        "## Clear existing checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYaZoeNeGrvo"
      },
      "source": [
        "# import shutil\n",
        "\n",
        "# try:\n",
        "#     shutil.rmtree(checkpoint_dir)\n",
        "# except OSError as e:\n",
        "#     print(\"Error: %s : %s\" % (checkpoint_dir, e.strerror))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxRUhnmKsUj9"
      },
      "source": [
        "### Download Complete NSynth Guitar Subset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTVOibF9sb3y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71029ed7-b937-400b-d22c-d27bf0344880"
      },
      "source": [
        "dataset_dir = '/content/complete'\n",
        "train_dataset_dir = os.path.join(dataset_dir, 'train')\n",
        "valid_dataset_dir = os.path.join(dataset_dir, 'valid')\n",
        "test_dataset_dir = os.path.join(dataset_dir, 'test')\n",
        "\n",
        "train_tfrecord_file = os.path.join(train_dataset_dir, 'complete.tfrecord')\n",
        "valid_tfrecord_file = os.path.join(valid_dataset_dir, 'complete.tfrecord')\n",
        "test_tfrecord_file = os.path.join(test_dataset_dir, 'complete.tfrecord')\n",
        "\n",
        "if not os.path.exists(dataset_dir):\n",
        "  train = 'https://osr-tsoai.s3.amazonaws.com/complete/train/complete.tfrecord'\n",
        "  valid = 'https://osr-tsoai.s3.amazonaws.com/complete/valid/complete.tfrecord'\n",
        "  test = 'https://osr-tsoai.s3.amazonaws.com/complete/test/complete.tfrecord'\n",
        "\n",
        "  print(\"Downloading train dataset to {}\\n\".format(train_dataset_dir))\n",
        "  !mkdir -p \"$train_dataset_dir\"\n",
        "  !curl $train --output $train_tfrecord_file\n",
        "\n",
        "  print(\"\\nDownloading valid dataset to {}\\n\".format(valid_dataset_dir))\n",
        "  !mkdir -p \"$valid_dataset_dir\"\n",
        "  !curl $valid --output $valid_tfrecord_file\n",
        "\n",
        "  print(\"\\nDownloading test dataset to {}\\n\".format(test_dataset_dir))\n",
        "  !mkdir -p \"$test_dataset_dir\"\n",
        "  !curl $test --output $test_tfrecord_file"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading train dataset to /content/complete/train\n",
            "\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 10.3G  100 10.3G    0     0  42.2M      0  0:04:11  0:04:11 --:--:-- 43.5M\n",
            "\n",
            "Downloading valid dataset to /content/complete/valid\n",
            "\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  675M  100  675M    0     0  41.7M      0  0:00:16  0:00:16 --:--:-- 44.9M\n",
            "\n",
            "Downloading test dataset to /content/complete/test\n",
            "\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  211M  100  211M    0     0  37.8M      0  0:00:05  0:00:05 --:--:-- 44.5M\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9AWf8NpBiB4"
      },
      "source": [
        "## Define DataProvider class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6180WP6AkkJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f6eb36c-05fb-4655-8237-a972fb815fc2"
      },
      "source": [
        "import tensorflow as tf\n",
        "import ddsp.training.data as data\n",
        "\n",
        "class CompleteTFRecordProvider(data.RecordProvider):\n",
        "  def __init__(self,\n",
        "               file_pattern=None,\n",
        "               example_secs=4,\n",
        "               sample_rate=16000,\n",
        "               frame_rate=250,\n",
        "               map_func=None):\n",
        "    super().__init__(file_pattern, example_secs, sample_rate,\n",
        "                      frame_rate, tf.data.TFRecordDataset)\n",
        "    self._map_func = map_func\n",
        "\n",
        "  def get_dataset(self, shuffle=True):\n",
        "    def parse_tfexample(record):\n",
        "      features = tf.io.parse_single_example(record, self.features_dict)\n",
        "      if self._map_func is not None:\n",
        "        return self._map_func(features)\n",
        "      else:\n",
        "        return features\n",
        "\n",
        "    filenames = tf.data.Dataset.list_files(self._file_pattern, shuffle=shuffle)\n",
        "    dataset = filenames.interleave(\n",
        "        map_func=self._data_format_map_fn,\n",
        "        cycle_length=40,\n",
        "        num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "    dataset = dataset.map(parse_tfexample,\n",
        "                          num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "    return dataset\n",
        "\n",
        "  @property\n",
        "  def features_dict(self):\n",
        "    return {\n",
        "      'sample_name':\n",
        "        tf.io.FixedLenFeature([1], dtype=tf.string),\n",
        "      'note_number':\n",
        "        tf.io.FixedLenFeature([1], dtype=tf.int64),\n",
        "      'velocity':\n",
        "        tf.io.FixedLenFeature([1], dtype=tf.int64),\n",
        "      'instrument_source':\n",
        "        tf.io.FixedLenFeature([1], dtype=tf.int64),\n",
        "      'qualities':\n",
        "        tf.io.FixedLenFeature([10], dtype=tf.int64),\n",
        "      'audio':\n",
        "        tf.io.FixedLenFeature([self._audio_length], dtype=tf.float32),\n",
        "      'f0_hz':\n",
        "        tf.io.FixedLenFeature([self._feature_length], dtype=tf.float32),\n",
        "      'f0_confidence':\n",
        "        tf.io.FixedLenFeature([self._feature_length], dtype=tf.float32),\n",
        "      'loudness_db':\n",
        "        tf.io.FixedLenFeature([self._feature_length], dtype=tf.float32),\n",
        "      'f0_scaled':\n",
        "        tf.io.FixedLenFeature([self._feature_length], dtype=tf.float32),\n",
        "      'ld_scaled':\n",
        "        tf.io.FixedLenFeature([self._feature_length], dtype=tf.float32),\n",
        "      'z':\n",
        "        tf.io.FixedLenFeature([self._feature_length * 16], dtype=tf.float32),\n",
        "    }"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:Argument whitelist is deprecated. Please use allowlist.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbUpwtyRB8wV"
      },
      "source": [
        "## Define features map function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NbXhqrZaB5rw"
      },
      "source": [
        "def features_map(features):\n",
        "    note_number = features['note_number']\n",
        "    velocity = features['velocity']\n",
        "    instrument_source = features['instrument_source']\n",
        "    qualities = features['qualities']\n",
        "    f0_scaled = features['f0_scaled']\n",
        "    ld_scaled = features['ld_scaled']\n",
        "    z = features['z']\n",
        "\n",
        "    sequence_length = f0_scaled.shape[0]\n",
        "\n",
        "    # compute outputs\n",
        "    f0_variation = f0_scaled * 127.0 - tf.cast(note_number, dtype=tf.float32)\n",
        "    # f0_variation = tf.clip_by_value(f0_variation, -1.0, 1.0)\n",
        "    f0_variation *= tf.cast(tf.math.less_equal(tf.math.abs(f0_variation), 1.0),\n",
        "                            dtype=tf.float32)\n",
        "    f0_variation = tf.expand_dims(f0_variation, axis=-1)\n",
        "    ld_scaled = tf.expand_dims(ld_scaled, axis=-1)\n",
        "    z = tf.reshape(z, shape=(sequence_length, 16))\n",
        "\n",
        "    # compute inputs\n",
        "    note_number = tf.squeeze(tf.one_hot(note_number, 128))\n",
        "    velocity = tf.squeeze(tf.one_hot(velocity, 128))\n",
        "    instrument_source = tf.squeeze(tf.one_hot(instrument_source, 3))\n",
        "    qualities = tf.cast(qualities, dtype=tf.float32)\n",
        "    input_z = tf.math.reduce_mean(z, axis=0)\n",
        "\n",
        "    # construct input output vectors\n",
        "    inputs = tf.concat(\n",
        "        [note_number, velocity, instrument_source, qualities, input_z],\n",
        "        axis=-1)\n",
        "    inputs = tf.expand_dims(inputs, axis=0)\n",
        "\n",
        "    targets = tf.concat(\n",
        "        [f0_variation, ld_scaled, z],\n",
        "        axis=-1)\n",
        "\n",
        "    inputs = {\n",
        "        'inputs': inputs,\n",
        "        'targets': tf.pad(targets[1::, :], [[1, 0], [0, 0]])\n",
        "    }\n",
        "\n",
        "    return inputs, targets"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7dYOU811Ni4"
      },
      "source": [
        "## Create datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBa055Xy1MIL"
      },
      "source": [
        "batch_size = 16\n",
        "example_secs = 4\n",
        "sample_rate = 16000\n",
        "frame_rate = 250\n",
        "\n",
        "# Create train dataset\n",
        "train_data_provider = CompleteTFRecordProvider(\n",
        "    file_pattern=train_tfrecord_file + '*',\n",
        "    example_secs=example_secs,\n",
        "    sample_rate=sample_rate,\n",
        "    frame_rate=frame_rate,\n",
        "    map_func=features_map)\n",
        "\n",
        "train_dataset = train_data_provider.get_batch(\n",
        "    batch_size,\n",
        "    shuffle=True,\n",
        "    repeats=-1)\n",
        "\n",
        "# Create valid dataset\n",
        "valid_data_provider = CompleteTFRecordProvider(\n",
        "    file_pattern=valid_tfrecord_file + '*',\n",
        "    example_secs=example_secs,\n",
        "    sample_rate=sample_rate,\n",
        "    frame_rate=frame_rate,\n",
        "    map_func=features_map)\n",
        "\n",
        "valid_dataset = valid_data_provider.get_batch(\n",
        "    batch_size,\n",
        "    shuffle=True,\n",
        "    repeats=-1)\n",
        "\n",
        "# Create test dataset\n",
        "test_data_provider = CompleteTFRecordProvider(\n",
        "    file_pattern=test_tfrecord_file + '*',\n",
        "    example_secs=example_secs,\n",
        "    sample_rate=sample_rate,\n",
        "    frame_rate=frame_rate,\n",
        "    map_func=features_map)\n",
        "\n",
        "test_dataset = test_data_provider.get_batch(\n",
        "    batch_size,\n",
        "    shuffle=True,\n",
        "    repeats=-1)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVxCGOXOY4Ab"
      },
      "source": [
        "# Transformer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sha2F2FdZDOJ"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def create_look_ahead_mask(size):\n",
        "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
        "    return mask  # (seq_len, seq_len)\n",
        "\n",
        "\n",
        "def get_angles(pos, i, d_model):\n",
        "    angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(d_model))\n",
        "    return pos * angle_rates\n",
        "\n",
        "\n",
        "def positional_encoding(position, d_model):\n",
        "    angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
        "                            np.arange(d_model)[np.newaxis, :],\n",
        "                            d_model)\n",
        "\n",
        "    # apply sin to even indices in the array; 2i\n",
        "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
        "\n",
        "    # apply cos to odd indices in the array; 2i+1\n",
        "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
        "\n",
        "    pos_encoding = angle_rads[np.newaxis, ...]\n",
        "\n",
        "    return tf.cast(pos_encoding, dtype=tf.float32)\n",
        "\n",
        "\n",
        "def scaled_dot_product_attention(q, k, v, mask):\n",
        "    \"\"\"Calculate the attention weights.\n",
        "    q, k, v must have matching leading dimensions.\n",
        "    k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
        "    The mask has different shapes depending on its type(padding or look ahead)\n",
        "    but it must be broadcastable for addition.\n",
        "\n",
        "    Args:\n",
        "      q: query shape == (..., seq_len_q, depth)\n",
        "      k: key shape == (..., seq_len_k, depth)\n",
        "      v: value shape == (..., seq_len_v, depth_v)\n",
        "      mask: Float tensor with shape broadcastable\n",
        "            to (..., seq_len_q, seq_len_k). Defaults to None.\n",
        "\n",
        "    Returns:\n",
        "      output, attention_weights\n",
        "    \"\"\"\n",
        "\n",
        "    matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
        "\n",
        "    # scale matmul_qk\n",
        "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
        "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
        "\n",
        "    # add the mask to the scaled tensor.\n",
        "    if mask is not None:\n",
        "        scaled_attention_logits += (mask * -1e9)\n",
        "\n",
        "    # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
        "    # add up to 1.\n",
        "    # (..., seq_len_q, seq_len_k)\n",
        "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)\n",
        "\n",
        "    # (..., seq_len_q, depth_v)\n",
        "    output = tf.matmul(attention_weights, v)\n",
        "\n",
        "    return output, attention_weights\n",
        "\n",
        "\n",
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.d_model = d_model\n",
        "\n",
        "        assert d_model % self.num_heads == 0\n",
        "\n",
        "        self.depth = d_model // self.num_heads\n",
        "\n",
        "        self.wq = tf.keras.layers.Dense(d_model)\n",
        "        self.wk = tf.keras.layers.Dense(d_model)\n",
        "        self.wv = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "        self.dense = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "    def split_heads(self, x, batch_size):\n",
        "        \"\"\"Split the last dimension into (num_heads, depth).\n",
        "        Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
        "        \"\"\"\n",
        "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
        "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "\n",
        "    def call(self, v, k, q, mask):\n",
        "        batch_size = tf.shape(q)[0]\n",
        "\n",
        "        q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
        "        k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
        "        v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
        "\n",
        "        # (batch_size, num_heads, seq_len_q, depth)\n",
        "        q = self.split_heads(q, batch_size)\n",
        "        # (batch_size, num_heads, seq_len_k, depth)\n",
        "        k = self.split_heads(k, batch_size)\n",
        "        # (batch_size, num_heads, seq_len_v, depth)\n",
        "        v = self.split_heads(v, batch_size)\n",
        "\n",
        "        # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
        "        # attention_weights.shape ==\n",
        "        # (batch_size, num_heads, seq_len_q, seq_len_k)\n",
        "        scaled_attention, attention_weights = scaled_dot_product_attention(\n",
        "            q, k, v, mask)\n",
        "\n",
        "        # (batch_size, seq_len_q, num_heads, depth)\n",
        "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
        "\n",
        "        # (batch_size, seq_len_q, d_model)\n",
        "        concat_attention = tf.reshape(scaled_attention,\n",
        "                                      (batch_size, -1, self.d_model))\n",
        "\n",
        "        # (batch_size, seq_len_q, d_model)\n",
        "        output = self.dense(concat_attention)\n",
        "\n",
        "        return output, attention_weights\n",
        "\n",
        "\n",
        "def point_wise_feed_forward_network(d_model, dff):\n",
        "    return tf.keras.Sequential([\n",
        "        # (batch_size, seq_len, dff)\n",
        "        tf.keras.layers.Dense(dff, activation='relu'),\n",
        "        # (batch_size, seq_len, d_model)\n",
        "        tf.keras.layers.Dense(d_model)\n",
        "    ])\n",
        "\n",
        "\n",
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "\n",
        "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
        "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "\n",
        "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "    def call(self, x, training, mask):\n",
        "        # (batch_size, input_seq_len, d_model)\n",
        "        attn_output, _ = self.mha(x, x, x, mask)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        # (batch_size, input_seq_len, d_model)\n",
        "        out1 = self.layernorm1(x + attn_output)\n",
        "\n",
        "        # (batch_size, input_seq_len, d_model)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        # (batch_size, input_seq_len, d_model)\n",
        "        out2 = self.layernorm2(out1 + ffn_output)\n",
        "\n",
        "        return out2\n",
        "\n",
        "\n",
        "class DecoderLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "\n",
        "        self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
        "        self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
        "\n",
        "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "\n",
        "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "        self.dropout3 = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "    def call(self, x, enc_output, training,\n",
        "             look_ahead_mask, padding_mask):\n",
        "        # enc_output.shape == (batch_size, input_seq_len, d_model)\n",
        "\n",
        "        # (batch_size, target_seq_len, d_model)\n",
        "        attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)\n",
        "        attn1 = self.dropout1(attn1, training=training)\n",
        "        out1 = self.layernorm1(attn1 + x)\n",
        "\n",
        "        attn2, attn_weights_block2 = self.mha2(\n",
        "            enc_output, enc_output, out1,\n",
        "            padding_mask)  # (batch_size, target_seq_len, d_model)\n",
        "        attn2 = self.dropout2(attn2, training=training)\n",
        "        out2 = self.layernorm2(\n",
        "            attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
        "\n",
        "        ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
        "        ffn_output = self.dropout3(ffn_output, training=training)\n",
        "        out3 = self.layernorm3(\n",
        "            ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n",
        "\n",
        "        return out3, attn_weights_block1, attn_weights_block2"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQaueb_AbcOK"
      },
      "source": [
        "def ffn(input_shape, num_layers, d_model, dff, rate=0.1):\n",
        "    inputs = tf.keras.layers.Input(shape=input_shape)\n",
        "    x = tf.keras.layers.Dense(dff)(inputs)\n",
        "    x = tf.keras.layers.LayerNormalization()(x)\n",
        "\n",
        "    for i in range(num_layers):\n",
        "        y = tf.keras.layers.Dense(dff, activation='relu')(x)\n",
        "        y = tf.keras.layers.Dropout(rate)(y)\n",
        "        x = tf.keras.layers.Add()([x, y])\n",
        "        x = tf.keras.layers.LayerNormalization()(x)\n",
        "\n",
        "    outputs = tf.keras.layers.Dense(d_model)(x)\n",
        "    return tf.keras.Model(inputs, outputs)\n",
        "\n",
        "\n",
        "class Encoder(tf.keras.layers.Layer):\n",
        "    def __init__(self, num_inputs, num_layers, d_model, dff, rate=0.1):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        self.ffn = ffn(\n",
        "            input_shape=(None, num_inputs),\n",
        "            num_layers=num_layers,\n",
        "            d_model=d_model,\n",
        "            dff=dff,\n",
        "            rate=rate)\n",
        "\n",
        "    def call(self, x, training):\n",
        "        return self.ffn(x, training=training)\n",
        "\n",
        "\n",
        "class Decoder(tf.keras.layers.Layer):\n",
        "    def __init__(self, num_outputs, num_layers, d_model, num_heads, dff,\n",
        "                 max_seq_len, rate=0.1):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding = ffn(\n",
        "            input_shape=(None, num_outputs),\n",
        "            num_layers=4,\n",
        "            d_model=d_model,\n",
        "            dff=dff,\n",
        "            rate=rate)\n",
        "\n",
        "        self.pos_encoding = positional_encoding(max_seq_len, d_model)\n",
        "\n",
        "        self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate)\n",
        "                           for _ in range(num_layers)]\n",
        "        self.dropout = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "    def call(self, x, enc_output, training, look_ahead_mask):\n",
        "        seq_len = tf.shape(x)[1]\n",
        "        attention_weights = {}\n",
        "\n",
        "        # (batch_size, target_seq_len, d_model)\n",
        "        x = self.embedding(x, training=training)\n",
        "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "        x += self.pos_encoding[:, :seq_len, :]\n",
        "\n",
        "        x = self.dropout(x, training=training)\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            x, block1, block2 = self.dec_layers[i](x, enc_output, training,\n",
        "                                                   look_ahead_mask,\n",
        "                                                   None)\n",
        "\n",
        "            attention_weights['decoder_layer{}_block1'.format(i + 1)] = block1\n",
        "            attention_weights['decoder_layer{}_block2'.format(i + 1)] = block2\n",
        "\n",
        "        # x.shape == (batch_size, target_seq_len, d_model)\n",
        "        return x, attention_weights\n",
        "\n",
        "\n",
        "class Transformer(tf.keras.Model):\n",
        "    def __init__(self, num_layers, d_model, num_heads, dff, max_seq_len,\n",
        "                 num_inputs, num_outputs, rate=0.1):\n",
        "        super(Transformer, self).__init__()\n",
        "\n",
        "        self.num_inputs = num_inputs\n",
        "        self.num_outputs = num_outputs\n",
        "        self.max_seq_len = max_seq_len\n",
        "\n",
        "        self.encoder = Encoder(num_inputs, num_layers, d_model, dff, rate)\n",
        "\n",
        "        self.decoder = Decoder(num_outputs, num_layers, d_model, num_heads, dff,\n",
        "                               max_seq_len, rate)\n",
        "\n",
        "        self.final_layer = tf.keras.layers.Dense(num_outputs)\n",
        "\n",
        "    def call(self, inputs, training=None, mask=None):\n",
        "        inp = inputs['inputs']\n",
        "        tar = inputs['targets']\n",
        "\n",
        "        # (batch_size, inp_seq_len, d_model)\n",
        "        enc_output = self.encoder(inp, training)\n",
        "\n",
        "        seq_len = tf.shape(tar)[1]\n",
        "        look_ahead_mask = create_look_ahead_mask(seq_len)\n",
        "\n",
        "        # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
        "        dec_output, attention_weights = self.decoder(\n",
        "            tar, enc_output, training, look_ahead_mask)\n",
        "\n",
        "        # (batch_size, tar_seq_len, target_vocab_size)\n",
        "        final_output = self.final_layer(dec_output)\n",
        "\n",
        "        return final_output\n",
        "\n",
        "    def compute_outputs(self, inputs):\n",
        "        batch_size = tf.shape(inputs)[0]\n",
        "        outputs = tf.zeros(shape=(batch_size, 1, self.num_outputs),\n",
        "                           dtype=tf.float32)\n",
        "\n",
        "        for i in range(self.max_seq_len):\n",
        "            input_dict = {\n",
        "                'inputs': inputs,\n",
        "                'targets': outputs\n",
        "            }\n",
        "\n",
        "            _outputs = self(input_dict, training=False)\n",
        "\n",
        "            outputs = tf.concat([outputs, _outputs[:, -1:, :]], axis=1)\n",
        "\n",
        "        return outputs"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RlGxnlpUervM"
      },
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "  def __init__(self, d_model, warmup_steps=4000):\n",
        "    super(CustomSchedule, self).__init__()\n",
        "    \n",
        "    self.d_model = d_model\n",
        "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "    self.warmup_steps = warmup_steps\n",
        "    \n",
        "  def __call__(self, step):\n",
        "    arg1 = tf.math.rsqrt(step)\n",
        "    arg2 = step * (self.warmup_steps ** -1.5)\n",
        "    \n",
        "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTiP6aA82Uay"
      },
      "source": [
        "# Create and compile mapping model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26aSTwuy2ZKy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f79371e-4740-4c61-f142-fa87d180d126"
      },
      "source": [
        "x_train, y_train = next(iter(train_dataset))\n",
        "\n",
        "num_inputs = x_train['inputs'].shape[-1]\n",
        "num_outputs = y_train.shape[-1]\n",
        "max_seq_len = y_train.shape[-2]\n",
        "\n",
        "print(num_inputs)\n",
        "print(num_outputs)\n",
        "print(max_seq_len)\n",
        "\n",
        "num_layers = 4\n",
        "d_model = 128\n",
        "num_heads = 4\n",
        "dff = 128\n",
        "\n",
        "model = Transformer(\n",
        "    num_layers=num_layers,\n",
        "    d_model=d_model,\n",
        "    num_heads=num_heads,\n",
        "    dff=dff,\n",
        "    max_seq_len=max_seq_len,\n",
        "    num_inputs=num_inputs,\n",
        "    num_outputs=num_outputs,\n",
        "    rate=0.1)\n",
        "\n",
        "loss = tf.keras.losses.MeanAbsoluteError()\n",
        "\n",
        "learning_rate = CustomSchedule(d_model)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, \n",
        "                                     epsilon=1e-9)\n",
        "\n",
        "model.compile(\n",
        "    optimizer=optimizer,  # tf.keras.optimizers.Adam(learning_rate=0.01),\n",
        "    loss=loss,\n",
        "    metrics=[tf.keras.losses.MeanSquaredError()])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "285\n",
            "18\n",
            "1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOBxsJYCGf-2"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "temp_learning_rate_schedule = CustomSchedule(d_model)\n",
        "\n",
        "plt.plot(temp_learning_rate_schedule(tf.range(40000, dtype=tf.float32)))\n",
        "plt.ylabel(\"Learning Rate\")\n",
        "plt.xlabel(\"Train Step\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zceUmkJI35zb"
      },
      "source": [
        "## Build model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qoczioW23-Da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2a1809e-0608-45fd-9f85-9a323754f38a"
      },
      "source": [
        "_ = model(x_train)\n",
        "\n",
        "print(model.summary())"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"transformer\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "encoder (Encoder)            multiple                  120448    \n",
            "_________________________________________________________________\n",
            "decoder (Decoder)            multiple                  749824    \n",
            "_________________________________________________________________\n",
            "dense_52 (Dense)             multiple                  2322      \n",
            "=================================================================\n",
            "Total params: 872,594\n",
            "Trainable params: 872,594\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SunnK0BY2utQ"
      },
      "source": [
        "# Load model checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gi46si8f2bOi"
      },
      "source": [
        "checkpoint_file = os.path.join(checkpoint_dir, 'cp.ckpt')\n",
        "\n",
        "if os.path.isdir(checkpoint_dir) and os.listdir(checkpoint_dir):\n",
        "    model.load_weights(checkpoint_file)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkCyoCxp3l7r"
      },
      "source": [
        "## Create training callbacks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23w7DNkh2ytf"
      },
      "source": [
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_file,\n",
        "    save_weights_only=False,\n",
        "    verbose=0,\n",
        "    save_freq='epoch')\n",
        "\n",
        "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20)\n",
        "\n",
        "# def scheduler(epoch, lr):\n",
        "#   if epoch < 10:\n",
        "#     return lr\n",
        "#   else:\n",
        "#     return lr * 0.9\n",
        "\n",
        "# lr_scheduler = tf.keras.callbacks.LearningRateScheduler(scheduler)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCkWXZD-5XsD"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xl4D5c_u5a1x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf885c3c-3146-4faf-a47f-aaf37ac41761"
      },
      "source": [
        "epochs = 500\n",
        "steps_per_epoch = 100\n",
        "validation_steps = 10\n",
        "\n",
        "model.fit(train_dataset,\n",
        "          epochs=epochs,\n",
        "          steps_per_epoch=steps_per_epoch,\n",
        "          validation_data=valid_dataset,\n",
        "          validation_steps=validation_steps,\n",
        "          callbacks=[checkpoint, early_stop])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "100/100 [==============================] - 30s 235ms/step - loss: 1.5668 - mean_squared_error: 4.1063 - val_loss: 1.1906 - val_mean_squared_error: 2.5596\n",
            "Epoch 2/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 1.2231 - mean_squared_error: 2.6813 - val_loss: 1.0625 - val_mean_squared_error: 2.1416\n",
            "Epoch 3/500\n",
            "100/100 [==============================] - 23s 228ms/step - loss: 1.0800 - mean_squared_error: 2.1760 - val_loss: 0.7815 - val_mean_squared_error: 1.1841\n",
            "Epoch 4/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.8098 - mean_squared_error: 1.2335 - val_loss: 0.5655 - val_mean_squared_error: 0.6328\n",
            "Epoch 5/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.6380 - mean_squared_error: 0.7613 - val_loss: 0.4194 - val_mean_squared_error: 0.3584\n",
            "Epoch 6/500\n",
            "100/100 [==============================] - 23s 228ms/step - loss: 0.5176 - mean_squared_error: 0.5069 - val_loss: 0.3341 - val_mean_squared_error: 0.2271\n",
            "Epoch 7/500\n",
            "100/100 [==============================] - 23s 227ms/step - loss: 0.4394 - mean_squared_error: 0.3606 - val_loss: 0.2838 - val_mean_squared_error: 0.1609\n",
            "Epoch 8/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.3825 - mean_squared_error: 0.2742 - val_loss: 0.2434 - val_mean_squared_error: 0.1195\n",
            "Epoch 9/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.3441 - mean_squared_error: 0.2220 - val_loss: 0.2251 - val_mean_squared_error: 0.1016\n",
            "Epoch 10/500\n",
            "100/100 [==============================] - 23s 227ms/step - loss: 0.3131 - mean_squared_error: 0.1844 - val_loss: 0.2044 - val_mean_squared_error: 0.0840\n",
            "Epoch 11/500\n",
            "100/100 [==============================] - 23s 227ms/step - loss: 0.2864 - mean_squared_error: 0.1552 - val_loss: 0.1928 - val_mean_squared_error: 0.0741\n",
            "Epoch 12/500\n",
            "100/100 [==============================] - 23s 227ms/step - loss: 0.2686 - mean_squared_error: 0.1386 - val_loss: 0.1736 - val_mean_squared_error: 0.0621\n",
            "Epoch 13/500\n",
            "100/100 [==============================] - 23s 227ms/step - loss: 0.2529 - mean_squared_error: 0.1243 - val_loss: 0.1776 - val_mean_squared_error: 0.0621\n",
            "Epoch 14/500\n",
            "100/100 [==============================] - 23s 227ms/step - loss: 0.2403 - mean_squared_error: 0.1117 - val_loss: 0.1731 - val_mean_squared_error: 0.0600\n",
            "Epoch 15/500\n",
            "100/100 [==============================] - 23s 227ms/step - loss: 0.2302 - mean_squared_error: 0.1034 - val_loss: 0.1611 - val_mean_squared_error: 0.0523\n",
            "Epoch 16/500\n",
            "100/100 [==============================] - 23s 227ms/step - loss: 0.2215 - mean_squared_error: 0.0970 - val_loss: 0.1576 - val_mean_squared_error: 0.0505\n",
            "Epoch 17/500\n",
            "100/100 [==============================] - 23s 227ms/step - loss: 0.2159 - mean_squared_error: 0.0934 - val_loss: 0.1487 - val_mean_squared_error: 0.0454\n",
            "Epoch 18/500\n",
            "100/100 [==============================] - 23s 227ms/step - loss: 0.2077 - mean_squared_error: 0.0864 - val_loss: 0.1624 - val_mean_squared_error: 0.0531\n",
            "Epoch 19/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.2002 - mean_squared_error: 0.0800 - val_loss: 0.1628 - val_mean_squared_error: 0.0521\n",
            "Epoch 20/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.1953 - mean_squared_error: 0.0760 - val_loss: 0.1549 - val_mean_squared_error: 0.0474\n",
            "Epoch 21/500\n",
            "100/100 [==============================] - 23s 227ms/step - loss: 0.1905 - mean_squared_error: 0.0726 - val_loss: 0.1501 - val_mean_squared_error: 0.0445\n",
            "Epoch 22/500\n",
            "100/100 [==============================] - 23s 227ms/step - loss: 0.1834 - mean_squared_error: 0.0680 - val_loss: 0.1338 - val_mean_squared_error: 0.0372\n",
            "Epoch 23/500\n",
            "100/100 [==============================] - 23s 227ms/step - loss: 0.1800 - mean_squared_error: 0.0660 - val_loss: 0.1341 - val_mean_squared_error: 0.0369\n",
            "Epoch 24/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.1748 - mean_squared_error: 0.0619 - val_loss: 0.1293 - val_mean_squared_error: 0.0349\n",
            "Epoch 25/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.1727 - mean_squared_error: 0.0600 - val_loss: 0.1358 - val_mean_squared_error: 0.0377\n",
            "Epoch 26/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.1665 - mean_squared_error: 0.0570 - val_loss: 0.1193 - val_mean_squared_error: 0.0298\n",
            "Epoch 27/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.1632 - mean_squared_error: 0.0544 - val_loss: 0.1249 - val_mean_squared_error: 0.0317\n",
            "Epoch 28/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.1587 - mean_squared_error: 0.0517 - val_loss: 0.1229 - val_mean_squared_error: 0.0313\n",
            "Epoch 29/500\n",
            "100/100 [==============================] - 23s 227ms/step - loss: 0.1547 - mean_squared_error: 0.0480 - val_loss: 0.1193 - val_mean_squared_error: 0.0283\n",
            "Epoch 30/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.1508 - mean_squared_error: 0.0469 - val_loss: 0.1084 - val_mean_squared_error: 0.0236\n",
            "Epoch 31/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.1472 - mean_squared_error: 0.0441 - val_loss: 0.1069 - val_mean_squared_error: 0.0229\n",
            "Epoch 32/500\n",
            "100/100 [==============================] - 23s 229ms/step - loss: 0.1395 - mean_squared_error: 0.0395 - val_loss: 0.0933 - val_mean_squared_error: 0.0181\n",
            "Epoch 33/500\n",
            "100/100 [==============================] - 23s 228ms/step - loss: 0.1357 - mean_squared_error: 0.0376 - val_loss: 0.0970 - val_mean_squared_error: 0.0192\n",
            "Epoch 34/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.1337 - mean_squared_error: 0.0368 - val_loss: 0.0872 - val_mean_squared_error: 0.0157\n",
            "Epoch 35/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.1288 - mean_squared_error: 0.0338 - val_loss: 0.0910 - val_mean_squared_error: 0.0180\n",
            "Epoch 36/500\n",
            "100/100 [==============================] - 23s 225ms/step - loss: 0.1281 - mean_squared_error: 0.0332 - val_loss: 0.0812 - val_mean_squared_error: 0.0138\n",
            "Epoch 37/500\n",
            "100/100 [==============================] - 23s 225ms/step - loss: 0.1218 - mean_squared_error: 0.0303 - val_loss: 0.0807 - val_mean_squared_error: 0.0138\n",
            "Epoch 38/500\n",
            "100/100 [==============================] - 22s 225ms/step - loss: 0.1218 - mean_squared_error: 0.0307 - val_loss: 0.0811 - val_mean_squared_error: 0.0136\n",
            "Epoch 39/500\n",
            "100/100 [==============================] - 22s 225ms/step - loss: 0.1184 - mean_squared_error: 0.0290 - val_loss: 0.0743 - val_mean_squared_error: 0.0120\n",
            "Epoch 40/500\n",
            "100/100 [==============================] - 23s 225ms/step - loss: 0.1149 - mean_squared_error: 0.0275 - val_loss: 0.0763 - val_mean_squared_error: 0.0121\n",
            "Epoch 41/500\n",
            "100/100 [==============================] - 23s 227ms/step - loss: 0.1140 - mean_squared_error: 0.0270 - val_loss: 0.0680 - val_mean_squared_error: 0.0102\n",
            "Epoch 42/500\n",
            "100/100 [==============================] - 23s 227ms/step - loss: 0.1105 - mean_squared_error: 0.0255 - val_loss: 0.0632 - val_mean_squared_error: 0.0087\n",
            "Epoch 43/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.1073 - mean_squared_error: 0.0241 - val_loss: 0.0633 - val_mean_squared_error: 0.0087\n",
            "Epoch 44/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.1047 - mean_squared_error: 0.0229 - val_loss: 0.0642 - val_mean_squared_error: 0.0094\n",
            "Epoch 45/500\n",
            "100/100 [==============================] - 22s 225ms/step - loss: 0.1012 - mean_squared_error: 0.0217 - val_loss: 0.0626 - val_mean_squared_error: 0.0087\n",
            "Epoch 46/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0987 - mean_squared_error: 0.0208 - val_loss: 0.0609 - val_mean_squared_error: 0.0082\n",
            "Epoch 47/500\n",
            "100/100 [==============================] - 23s 225ms/step - loss: 0.0963 - mean_squared_error: 0.0198 - val_loss: 0.0530 - val_mean_squared_error: 0.0066\n",
            "Epoch 48/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0920 - mean_squared_error: 0.0185 - val_loss: 0.0485 - val_mean_squared_error: 0.0059\n",
            "Epoch 49/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0886 - mean_squared_error: 0.0172 - val_loss: 0.0528 - val_mean_squared_error: 0.0067\n",
            "Epoch 50/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0865 - mean_squared_error: 0.0167 - val_loss: 0.0484 - val_mean_squared_error: 0.0057\n",
            "Epoch 51/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0818 - mean_squared_error: 0.0148 - val_loss: 0.0528 - val_mean_squared_error: 0.0068\n",
            "Epoch 52/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0797 - mean_squared_error: 0.0145 - val_loss: 0.0471 - val_mean_squared_error: 0.0054\n",
            "Epoch 53/500\n",
            "100/100 [==============================] - 23s 225ms/step - loss: 0.0777 - mean_squared_error: 0.0137 - val_loss: 0.0476 - val_mean_squared_error: 0.0058\n",
            "Epoch 54/500\n",
            "100/100 [==============================] - 23s 225ms/step - loss: 0.0733 - mean_squared_error: 0.0126 - val_loss: 0.0449 - val_mean_squared_error: 0.0049\n",
            "Epoch 55/500\n",
            "100/100 [==============================] - 23s 225ms/step - loss: 0.0713 - mean_squared_error: 0.0119 - val_loss: 0.0384 - val_mean_squared_error: 0.0042\n",
            "Epoch 56/500\n",
            "100/100 [==============================] - 22s 225ms/step - loss: 0.0681 - mean_squared_error: 0.0111 - val_loss: 0.0383 - val_mean_squared_error: 0.0041\n",
            "Epoch 57/500\n",
            "100/100 [==============================] - 22s 225ms/step - loss: 0.0659 - mean_squared_error: 0.0107 - val_loss: 0.0430 - val_mean_squared_error: 0.0050\n",
            "Epoch 58/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0681 - mean_squared_error: 0.0113 - val_loss: 0.0390 - val_mean_squared_error: 0.0043\n",
            "Epoch 59/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0617 - mean_squared_error: 0.0094 - val_loss: 0.0381 - val_mean_squared_error: 0.0040\n",
            "Epoch 60/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0608 - mean_squared_error: 0.0095 - val_loss: 0.0358 - val_mean_squared_error: 0.0038\n",
            "Epoch 61/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0578 - mean_squared_error: 0.0084 - val_loss: 0.0293 - val_mean_squared_error: 0.0030\n",
            "Epoch 62/500\n",
            "100/100 [==============================] - 22s 225ms/step - loss: 0.0565 - mean_squared_error: 0.0083 - val_loss: 0.0343 - val_mean_squared_error: 0.0035\n",
            "Epoch 63/500\n",
            "100/100 [==============================] - 23s 225ms/step - loss: 0.0561 - mean_squared_error: 0.0083 - val_loss: 0.0343 - val_mean_squared_error: 0.0036\n",
            "Epoch 64/500\n",
            "100/100 [==============================] - 22s 225ms/step - loss: 0.0541 - mean_squared_error: 0.0080 - val_loss: 0.0289 - val_mean_squared_error: 0.0030\n",
            "Epoch 65/500\n",
            "100/100 [==============================] - 22s 225ms/step - loss: 0.0535 - mean_squared_error: 0.0078 - val_loss: 0.0267 - val_mean_squared_error: 0.0027\n",
            "Epoch 66/500\n",
            "100/100 [==============================] - 22s 225ms/step - loss: 0.0516 - mean_squared_error: 0.0073 - val_loss: 0.0282 - val_mean_squared_error: 0.0030\n",
            "Epoch 67/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0509 - mean_squared_error: 0.0072 - val_loss: 0.0316 - val_mean_squared_error: 0.0033\n",
            "Epoch 68/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0508 - mean_squared_error: 0.0071 - val_loss: 0.0289 - val_mean_squared_error: 0.0030\n",
            "Epoch 69/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0483 - mean_squared_error: 0.0066 - val_loss: 0.0294 - val_mean_squared_error: 0.0029\n",
            "Epoch 70/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0471 - mean_squared_error: 0.0064 - val_loss: 0.0291 - val_mean_squared_error: 0.0029\n",
            "Epoch 71/500\n",
            "100/100 [==============================] - 23s 225ms/step - loss: 0.0481 - mean_squared_error: 0.0068 - val_loss: 0.0250 - val_mean_squared_error: 0.0026\n",
            "Epoch 72/500\n",
            "100/100 [==============================] - 23s 225ms/step - loss: 0.0454 - mean_squared_error: 0.0060 - val_loss: 0.0248 - val_mean_squared_error: 0.0026\n",
            "Epoch 73/500\n",
            "100/100 [==============================] - 23s 225ms/step - loss: 0.0455 - mean_squared_error: 0.0061 - val_loss: 0.0258 - val_mean_squared_error: 0.0027\n",
            "Epoch 74/500\n",
            "100/100 [==============================] - 22s 225ms/step - loss: 0.0447 - mean_squared_error: 0.0059 - val_loss: 0.0252 - val_mean_squared_error: 0.0026\n",
            "Epoch 75/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0434 - mean_squared_error: 0.0057 - val_loss: 0.0231 - val_mean_squared_error: 0.0025\n",
            "Epoch 76/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0427 - mean_squared_error: 0.0056 - val_loss: 0.0249 - val_mean_squared_error: 0.0026\n",
            "Epoch 77/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0431 - mean_squared_error: 0.0055 - val_loss: 0.0214 - val_mean_squared_error: 0.0023\n",
            "Epoch 78/500\n",
            "100/100 [==============================] - 22s 225ms/step - loss: 0.0409 - mean_squared_error: 0.0053 - val_loss: 0.0227 - val_mean_squared_error: 0.0024\n",
            "Epoch 79/500\n",
            "100/100 [==============================] - 22s 225ms/step - loss: 0.0412 - mean_squared_error: 0.0053 - val_loss: 0.0216 - val_mean_squared_error: 0.0023\n",
            "Epoch 80/500\n",
            "100/100 [==============================] - 22s 225ms/step - loss: 0.0407 - mean_squared_error: 0.0053 - val_loss: 0.0238 - val_mean_squared_error: 0.0025\n",
            "Epoch 81/500\n",
            "100/100 [==============================] - 22s 225ms/step - loss: 0.0400 - mean_squared_error: 0.0051 - val_loss: 0.0254 - val_mean_squared_error: 0.0027\n",
            "Epoch 82/500\n",
            "100/100 [==============================] - 22s 225ms/step - loss: 0.0398 - mean_squared_error: 0.0050 - val_loss: 0.0280 - val_mean_squared_error: 0.0029\n",
            "Epoch 83/500\n",
            "100/100 [==============================] - 23s 225ms/step - loss: 0.0395 - mean_squared_error: 0.0051 - val_loss: 0.0204 - val_mean_squared_error: 0.0022\n",
            "Epoch 84/500\n",
            "100/100 [==============================] - 22s 225ms/step - loss: 0.0379 - mean_squared_error: 0.0048 - val_loss: 0.0247 - val_mean_squared_error: 0.0026\n",
            "Epoch 85/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0378 - mean_squared_error: 0.0047 - val_loss: 0.0216 - val_mean_squared_error: 0.0023\n",
            "Epoch 86/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0383 - mean_squared_error: 0.0049 - val_loss: 0.0201 - val_mean_squared_error: 0.0022\n",
            "Epoch 87/500\n",
            "100/100 [==============================] - 23s 225ms/step - loss: 0.0372 - mean_squared_error: 0.0047 - val_loss: 0.0208 - val_mean_squared_error: 0.0022\n",
            "Epoch 88/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0372 - mean_squared_error: 0.0047 - val_loss: 0.0203 - val_mean_squared_error: 0.0022\n",
            "Epoch 89/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0362 - mean_squared_error: 0.0046 - val_loss: 0.0214 - val_mean_squared_error: 0.0023\n",
            "Epoch 90/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0361 - mean_squared_error: 0.0047 - val_loss: 0.0229 - val_mean_squared_error: 0.0024\n",
            "Epoch 91/500\n",
            "100/100 [==============================] - 22s 225ms/step - loss: 0.0366 - mean_squared_error: 0.0047 - val_loss: 0.0211 - val_mean_squared_error: 0.0023\n",
            "Epoch 92/500\n",
            "100/100 [==============================] - 23s 225ms/step - loss: 0.0355 - mean_squared_error: 0.0046 - val_loss: 0.0181 - val_mean_squared_error: 0.0021\n",
            "Epoch 93/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0342 - mean_squared_error: 0.0044 - val_loss: 0.0208 - val_mean_squared_error: 0.0022\n",
            "Epoch 94/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0349 - mean_squared_error: 0.0044 - val_loss: 0.0192 - val_mean_squared_error: 0.0021\n",
            "Epoch 95/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0335 - mean_squared_error: 0.0041 - val_loss: 0.0193 - val_mean_squared_error: 0.0021\n",
            "Epoch 96/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0339 - mean_squared_error: 0.0040 - val_loss: 0.0220 - val_mean_squared_error: 0.0023\n",
            "Epoch 97/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0332 - mean_squared_error: 0.0041 - val_loss: 0.0170 - val_mean_squared_error: 0.0020\n",
            "Epoch 98/500\n",
            "100/100 [==============================] - 23s 225ms/step - loss: 0.0332 - mean_squared_error: 0.0041 - val_loss: 0.0176 - val_mean_squared_error: 0.0020\n",
            "Epoch 99/500\n",
            "100/100 [==============================] - 23s 225ms/step - loss: 0.0327 - mean_squared_error: 0.0041 - val_loss: 0.0168 - val_mean_squared_error: 0.0019\n",
            "Epoch 100/500\n",
            "100/100 [==============================] - 23s 225ms/step - loss: 0.0319 - mean_squared_error: 0.0039 - val_loss: 0.0198 - val_mean_squared_error: 0.0022\n",
            "Epoch 101/500\n",
            "100/100 [==============================] - 22s 225ms/step - loss: 0.0328 - mean_squared_error: 0.0042 - val_loss: 0.0204 - val_mean_squared_error: 0.0022\n",
            "Epoch 102/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0322 - mean_squared_error: 0.0039 - val_loss: 0.0168 - val_mean_squared_error: 0.0020\n",
            "Epoch 103/500\n",
            "100/100 [==============================] - 22s 225ms/step - loss: 0.0321 - mean_squared_error: 0.0040 - val_loss: 0.0182 - val_mean_squared_error: 0.0020\n",
            "Epoch 104/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0309 - mean_squared_error: 0.0038 - val_loss: 0.0156 - val_mean_squared_error: 0.0019\n",
            "Epoch 105/500\n",
            "100/100 [==============================] - 22s 225ms/step - loss: 0.0309 - mean_squared_error: 0.0040 - val_loss: 0.0175 - val_mean_squared_error: 0.0020\n",
            "Epoch 106/500\n",
            "100/100 [==============================] - 22s 225ms/step - loss: 0.0310 - mean_squared_error: 0.0038 - val_loss: 0.0158 - val_mean_squared_error: 0.0018\n",
            "Epoch 107/500\n",
            "100/100 [==============================] - 23s 225ms/step - loss: 0.0314 - mean_squared_error: 0.0038 - val_loss: 0.0163 - val_mean_squared_error: 0.0019\n",
            "Epoch 108/500\n",
            "100/100 [==============================] - 23s 225ms/step - loss: 0.0303 - mean_squared_error: 0.0036 - val_loss: 0.0160 - val_mean_squared_error: 0.0018\n",
            "Epoch 109/500\n",
            "100/100 [==============================] - 23s 225ms/step - loss: 0.0306 - mean_squared_error: 0.0037 - val_loss: 0.0156 - val_mean_squared_error: 0.0018\n",
            "Epoch 110/500\n",
            "100/100 [==============================] - 23s 225ms/step - loss: 0.0303 - mean_squared_error: 0.0036 - val_loss: 0.0143 - val_mean_squared_error: 0.0017\n",
            "Epoch 111/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0295 - mean_squared_error: 0.0035 - val_loss: 0.0175 - val_mean_squared_error: 0.0019\n",
            "Epoch 112/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0296 - mean_squared_error: 0.0036 - val_loss: 0.0216 - val_mean_squared_error: 0.0020\n",
            "Epoch 113/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0293 - mean_squared_error: 0.0034 - val_loss: 0.0148 - val_mean_squared_error: 0.0015\n",
            "Epoch 114/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0295 - mean_squared_error: 0.0035 - val_loss: 0.0153 - val_mean_squared_error: 0.0016\n",
            "Epoch 115/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0289 - mean_squared_error: 0.0033 - val_loss: 0.0139 - val_mean_squared_error: 0.0014\n",
            "Epoch 116/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0283 - mean_squared_error: 0.0032 - val_loss: 0.0147 - val_mean_squared_error: 0.0014\n",
            "Epoch 117/500\n",
            "100/100 [==============================] - 23s 225ms/step - loss: 0.0277 - mean_squared_error: 0.0030 - val_loss: 0.0141 - val_mean_squared_error: 0.0014\n",
            "Epoch 118/500\n",
            "100/100 [==============================] - 23s 225ms/step - loss: 0.0276 - mean_squared_error: 0.0030 - val_loss: 0.0140 - val_mean_squared_error: 0.0014\n",
            "Epoch 119/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0270 - mean_squared_error: 0.0029 - val_loss: 0.0132 - val_mean_squared_error: 0.0014\n",
            "Epoch 120/500\n",
            "100/100 [==============================] - 23s 225ms/step - loss: 0.0272 - mean_squared_error: 0.0030 - val_loss: 0.0166 - val_mean_squared_error: 0.0016\n",
            "Epoch 121/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0273 - mean_squared_error: 0.0029 - val_loss: 0.0134 - val_mean_squared_error: 0.0014\n",
            "Epoch 122/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0264 - mean_squared_error: 0.0029 - val_loss: 0.0118 - val_mean_squared_error: 0.0013\n",
            "Epoch 123/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0263 - mean_squared_error: 0.0029 - val_loss: 0.0126 - val_mean_squared_error: 0.0013\n",
            "Epoch 124/500\n",
            "100/100 [==============================] - 23s 225ms/step - loss: 0.0259 - mean_squared_error: 0.0028 - val_loss: 0.0133 - val_mean_squared_error: 0.0014\n",
            "Epoch 125/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0262 - mean_squared_error: 0.0029 - val_loss: 0.0126 - val_mean_squared_error: 0.0013\n",
            "Epoch 126/500\n",
            "100/100 [==============================] - 23s 225ms/step - loss: 0.0261 - mean_squared_error: 0.0029 - val_loss: 0.0139 - val_mean_squared_error: 0.0014\n",
            "Epoch 127/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0257 - mean_squared_error: 0.0028 - val_loss: 0.0138 - val_mean_squared_error: 0.0014\n",
            "Epoch 128/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0256 - mean_squared_error: 0.0028 - val_loss: 0.0149 - val_mean_squared_error: 0.0014\n",
            "Epoch 129/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0255 - mean_squared_error: 0.0028 - val_loss: 0.0151 - val_mean_squared_error: 0.0015\n",
            "Epoch 130/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0259 - mean_squared_error: 0.0028 - val_loss: 0.0134 - val_mean_squared_error: 0.0014\n",
            "Epoch 131/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0250 - mean_squared_error: 0.0027 - val_loss: 0.0139 - val_mean_squared_error: 0.0014\n",
            "Epoch 132/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0256 - mean_squared_error: 0.0029 - val_loss: 0.0122 - val_mean_squared_error: 0.0013\n",
            "Epoch 133/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0255 - mean_squared_error: 0.0028 - val_loss: 0.0147 - val_mean_squared_error: 0.0014\n",
            "Epoch 134/500\n",
            "100/100 [==============================] - 23s 225ms/step - loss: 0.0248 - mean_squared_error: 0.0027 - val_loss: 0.0133 - val_mean_squared_error: 0.0014\n",
            "Epoch 135/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0246 - mean_squared_error: 0.0027 - val_loss: 0.0136 - val_mean_squared_error: 0.0014\n",
            "Epoch 136/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0240 - mean_squared_error: 0.0026 - val_loss: 0.0129 - val_mean_squared_error: 0.0013\n",
            "Epoch 137/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0239 - mean_squared_error: 0.0025 - val_loss: 0.0112 - val_mean_squared_error: 0.0013\n",
            "Epoch 138/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0237 - mean_squared_error: 0.0026 - val_loss: 0.0125 - val_mean_squared_error: 0.0013\n",
            "Epoch 139/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0244 - mean_squared_error: 0.0026 - val_loss: 0.0113 - val_mean_squared_error: 0.0013\n",
            "Epoch 140/500\n",
            "100/100 [==============================] - 23s 225ms/step - loss: 0.0234 - mean_squared_error: 0.0026 - val_loss: 0.0115 - val_mean_squared_error: 0.0013\n",
            "Epoch 141/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0234 - mean_squared_error: 0.0026 - val_loss: 0.0134 - val_mean_squared_error: 0.0014\n",
            "Epoch 142/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0236 - mean_squared_error: 0.0027 - val_loss: 0.0126 - val_mean_squared_error: 0.0013\n",
            "Epoch 143/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0234 - mean_squared_error: 0.0025 - val_loss: 0.0114 - val_mean_squared_error: 0.0013\n",
            "Epoch 144/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0232 - mean_squared_error: 0.0025 - val_loss: 0.0132 - val_mean_squared_error: 0.0014\n",
            "Epoch 145/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0231 - mean_squared_error: 0.0026 - val_loss: 0.0125 - val_mean_squared_error: 0.0013\n",
            "Epoch 146/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0236 - mean_squared_error: 0.0026 - val_loss: 0.0128 - val_mean_squared_error: 0.0014\n",
            "Epoch 147/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0230 - mean_squared_error: 0.0026 - val_loss: 0.0125 - val_mean_squared_error: 0.0013\n",
            "Epoch 148/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0234 - mean_squared_error: 0.0025 - val_loss: 0.0110 - val_mean_squared_error: 0.0013\n",
            "Epoch 149/500\n",
            "100/100 [==============================] - 23s 225ms/step - loss: 0.0230 - mean_squared_error: 0.0025 - val_loss: 0.0122 - val_mean_squared_error: 0.0013\n",
            "Epoch 150/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0225 - mean_squared_error: 0.0024 - val_loss: 0.0122 - val_mean_squared_error: 0.0013\n",
            "Epoch 151/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0237 - mean_squared_error: 0.0026 - val_loss: 0.0122 - val_mean_squared_error: 0.0013\n",
            "Epoch 152/500\n",
            "100/100 [==============================] - 23s 225ms/step - loss: 0.0226 - mean_squared_error: 0.0025 - val_loss: 0.0110 - val_mean_squared_error: 0.0013\n",
            "Epoch 153/500\n",
            "100/100 [==============================] - 22s 225ms/step - loss: 0.0221 - mean_squared_error: 0.0024 - val_loss: 0.0153 - val_mean_squared_error: 0.0014\n",
            "Epoch 154/500\n",
            "100/100 [==============================] - 23s 225ms/step - loss: 0.0235 - mean_squared_error: 0.0025 - val_loss: 0.0115 - val_mean_squared_error: 0.0013\n",
            "Epoch 155/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0223 - mean_squared_error: 0.0025 - val_loss: 0.0099 - val_mean_squared_error: 0.0012\n",
            "Epoch 156/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0228 - mean_squared_error: 0.0025 - val_loss: 0.0112 - val_mean_squared_error: 0.0013\n",
            "Epoch 157/500\n",
            "100/100 [==============================] - 23s 225ms/step - loss: 0.0226 - mean_squared_error: 0.0025 - val_loss: 0.0101 - val_mean_squared_error: 0.0012\n",
            "Epoch 158/500\n",
            "100/100 [==============================] - 22s 225ms/step - loss: 0.0215 - mean_squared_error: 0.0024 - val_loss: 0.0126 - val_mean_squared_error: 0.0013\n",
            "Epoch 159/500\n",
            "100/100 [==============================] - 23s 225ms/step - loss: 0.0227 - mean_squared_error: 0.0025 - val_loss: 0.0104 - val_mean_squared_error: 0.0013\n",
            "Epoch 160/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0213 - mean_squared_error: 0.0024 - val_loss: 0.0111 - val_mean_squared_error: 0.0013\n",
            "Epoch 161/500\n",
            "100/100 [==============================] - 23s 225ms/step - loss: 0.0214 - mean_squared_error: 0.0024 - val_loss: 0.0108 - val_mean_squared_error: 0.0013\n",
            "Epoch 162/500\n",
            "100/100 [==============================] - 23s 225ms/step - loss: 0.0217 - mean_squared_error: 0.0024 - val_loss: 0.0109 - val_mean_squared_error: 0.0013\n",
            "Epoch 163/500\n",
            "100/100 [==============================] - 23s 225ms/step - loss: 0.0217 - mean_squared_error: 0.0024 - val_loss: 0.0128 - val_mean_squared_error: 0.0014\n",
            "Epoch 164/500\n",
            "100/100 [==============================] - 23s 227ms/step - loss: 0.0219 - mean_squared_error: 0.0024 - val_loss: 0.0113 - val_mean_squared_error: 0.0013\n",
            "Epoch 165/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0212 - mean_squared_error: 0.0024 - val_loss: 0.0109 - val_mean_squared_error: 0.0013\n",
            "Epoch 166/500\n",
            "100/100 [==============================] - 23s 225ms/step - loss: 0.0216 - mean_squared_error: 0.0024 - val_loss: 0.0117 - val_mean_squared_error: 0.0013\n",
            "Epoch 167/500\n",
            "100/100 [==============================] - 23s 225ms/step - loss: 0.0210 - mean_squared_error: 0.0024 - val_loss: 0.0116 - val_mean_squared_error: 0.0013\n",
            "Epoch 168/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0211 - mean_squared_error: 0.0024 - val_loss: 0.0127 - val_mean_squared_error: 0.0013\n",
            "Epoch 169/500\n",
            "100/100 [==============================] - 23s 225ms/step - loss: 0.0212 - mean_squared_error: 0.0024 - val_loss: 0.0109 - val_mean_squared_error: 0.0013\n",
            "Epoch 170/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0215 - mean_squared_error: 0.0024 - val_loss: 0.0110 - val_mean_squared_error: 0.0013\n",
            "Epoch 171/500\n",
            "100/100 [==============================] - 22s 225ms/step - loss: 0.0214 - mean_squared_error: 0.0024 - val_loss: 0.0113 - val_mean_squared_error: 0.0013\n",
            "Epoch 172/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0207 - mean_squared_error: 0.0024 - val_loss: 0.0111 - val_mean_squared_error: 0.0013\n",
            "Epoch 173/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0211 - mean_squared_error: 0.0024 - val_loss: 0.0099 - val_mean_squared_error: 0.0012\n",
            "Epoch 174/500\n",
            "100/100 [==============================] - 23s 227ms/step - loss: 0.0204 - mean_squared_error: 0.0023 - val_loss: 0.0115 - val_mean_squared_error: 0.0013\n",
            "Epoch 175/500\n",
            "100/100 [==============================] - 23s 227ms/step - loss: 0.0204 - mean_squared_error: 0.0023 - val_loss: 0.0094 - val_mean_squared_error: 0.0012\n",
            "Epoch 176/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0208 - mean_squared_error: 0.0024 - val_loss: 0.0111 - val_mean_squared_error: 0.0013\n",
            "Epoch 177/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0203 - mean_squared_error: 0.0023 - val_loss: 0.0112 - val_mean_squared_error: 0.0013\n",
            "Epoch 178/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0204 - mean_squared_error: 0.0022 - val_loss: 0.0102 - val_mean_squared_error: 0.0012\n",
            "Epoch 179/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0203 - mean_squared_error: 0.0023 - val_loss: 0.0115 - val_mean_squared_error: 0.0013\n",
            "Epoch 180/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0208 - mean_squared_error: 0.0023 - val_loss: 0.0100 - val_mean_squared_error: 0.0012\n",
            "Epoch 181/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0203 - mean_squared_error: 0.0023 - val_loss: 0.0096 - val_mean_squared_error: 0.0012\n",
            "Epoch 182/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0202 - mean_squared_error: 0.0023 - val_loss: 0.0111 - val_mean_squared_error: 0.0013\n",
            "Epoch 183/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0204 - mean_squared_error: 0.0023 - val_loss: 0.0129 - val_mean_squared_error: 0.0013\n",
            "Epoch 184/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0203 - mean_squared_error: 0.0023 - val_loss: 0.0106 - val_mean_squared_error: 0.0012\n",
            "Epoch 185/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0199 - mean_squared_error: 0.0023 - val_loss: 0.0111 - val_mean_squared_error: 0.0013\n",
            "Epoch 186/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0198 - mean_squared_error: 0.0022 - val_loss: 0.0151 - val_mean_squared_error: 0.0014\n",
            "Epoch 187/500\n",
            "100/100 [==============================] - 23s 227ms/step - loss: 0.0204 - mean_squared_error: 0.0023 - val_loss: 0.0093 - val_mean_squared_error: 0.0012\n",
            "Epoch 188/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0194 - mean_squared_error: 0.0022 - val_loss: 0.0100 - val_mean_squared_error: 0.0012\n",
            "Epoch 189/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0197 - mean_squared_error: 0.0022 - val_loss: 0.0099 - val_mean_squared_error: 0.0012\n",
            "Epoch 190/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0194 - mean_squared_error: 0.0022 - val_loss: 0.0121 - val_mean_squared_error: 0.0013\n",
            "Epoch 191/500\n",
            "100/100 [==============================] - 23s 227ms/step - loss: 0.0196 - mean_squared_error: 0.0022 - val_loss: 0.0104 - val_mean_squared_error: 0.0012\n",
            "Epoch 192/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0198 - mean_squared_error: 0.0023 - val_loss: 0.0098 - val_mean_squared_error: 0.0012\n",
            "Epoch 193/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0197 - mean_squared_error: 0.0023 - val_loss: 0.0094 - val_mean_squared_error: 0.0012\n",
            "Epoch 194/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0194 - mean_squared_error: 0.0023 - val_loss: 0.0112 - val_mean_squared_error: 0.0013\n",
            "Epoch 195/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0192 - mean_squared_error: 0.0023 - val_loss: 0.0099 - val_mean_squared_error: 0.0012\n",
            "Epoch 196/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0192 - mean_squared_error: 0.0022 - val_loss: 0.0096 - val_mean_squared_error: 0.0012\n",
            "Epoch 197/500\n",
            "100/100 [==============================] - 23s 225ms/step - loss: 0.0190 - mean_squared_error: 0.0023 - val_loss: 0.0106 - val_mean_squared_error: 0.0012\n",
            "Epoch 198/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0196 - mean_squared_error: 0.0022 - val_loss: 0.0094 - val_mean_squared_error: 0.0012\n",
            "Epoch 199/500\n",
            "100/100 [==============================] - 23s 227ms/step - loss: 0.0190 - mean_squared_error: 0.0022 - val_loss: 0.0094 - val_mean_squared_error: 0.0012\n",
            "Epoch 200/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0189 - mean_squared_error: 0.0022 - val_loss: 0.0096 - val_mean_squared_error: 0.0012\n",
            "Epoch 201/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0189 - mean_squared_error: 0.0022 - val_loss: 0.0108 - val_mean_squared_error: 0.0012\n",
            "Epoch 202/500\n",
            "100/100 [==============================] - 23s 227ms/step - loss: 0.0187 - mean_squared_error: 0.0021 - val_loss: 0.0100 - val_mean_squared_error: 0.0012\n",
            "Epoch 203/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0189 - mean_squared_error: 0.0022 - val_loss: 0.0101 - val_mean_squared_error: 0.0012\n",
            "Epoch 204/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0184 - mean_squared_error: 0.0021 - val_loss: 0.0096 - val_mean_squared_error: 0.0012\n",
            "Epoch 205/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0187 - mean_squared_error: 0.0021 - val_loss: 0.0095 - val_mean_squared_error: 0.0012\n",
            "Epoch 206/500\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0184 - mean_squared_error: 0.0022 - val_loss: 0.0101 - val_mean_squared_error: 0.0012\n",
            "Epoch 207/500\n",
            "100/100 [==============================] - 23s 227ms/step - loss: 0.0188 - mean_squared_error: 0.0022 - val_loss: 0.0102 - val_mean_squared_error: 0.0012\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd6100391d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNyLeJcN6wS8"
      },
      "source": [
        "## Evaluate model on test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hX4SXagL6vwB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d836425-a501-4c07-beb3-bc552f7962eb"
      },
      "source": [
        "model.evaluate(test_dataset, steps=500)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "500/500 [==============================] - 46s 92ms/step - loss: 0.0101 - mean_squared_error: 0.0012\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.010110861621797085, 0.001246755593456328]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    }
  ]
}