{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "residential-length",
   "metadata": {},
   "source": [
    "## A Basic Causal Convolution Mapping Network\n",
    "\n",
    "---\n",
    "\n",
    "![Model](images/causal_conv_1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "operating-badge",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.layers import Input, concatenate, Conv1D, MaxPool1D, Flatten\n",
    "from tensorflow.keras.layers import Dense, Reshape, GlobalAveragePooling1D\n",
    "from mapping_models import trainer\n",
    "\n",
    "print(tf.config.list_physical_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inner-thing",
   "metadata": {},
   "source": [
    "## Create Feature Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funded-bangkok",
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_map(features):\n",
    "    def convert_to_sequence(feature):\n",
    "        channels = feature.shape[0]\n",
    "        feature = tf.expand_dims(feature, axis=0)\n",
    "\n",
    "        feature = tf.broadcast_to(feature, shape=(sequence_length, channels))\n",
    "        feature = tf.cast(feature, dtype=tf.float32)\n",
    "\n",
    "        return feature\n",
    "\n",
    "    note_number = features['note_number']\n",
    "    velocity = features['velocity']\n",
    "    instrument_source = features['instrument_source']\n",
    "    qualities = features['qualities']\n",
    "    f0_scaled = features['f0_scaled']\n",
    "    ld_scaled = features['ld_scaled']\n",
    "    z = features['z']\n",
    "\n",
    "    sequence_length = f0_scaled.shape[0]\n",
    "\n",
    "    # Normalize data\n",
    "    # 0-127\n",
    "    note_number = note_number / 127\n",
    "    velocity = velocity / 127\n",
    "\n",
    "    # 0-2\n",
    "    # 0\tacoustic, 1\telectronic, 2\tsynthetic\n",
    "    instrument_source = instrument_source / 2\n",
    "\n",
    "    # Prepare dataset for a sequence to sequence mapping\n",
    "    note_number = convert_to_sequence(note_number) # 1000, 1\n",
    "    velocity = convert_to_sequence(velocity)\n",
    "    instrument_source = convert_to_sequence(instrument_source)\n",
    "    qualities = convert_to_sequence(qualities) # 1000, 10\n",
    "\n",
    "    f0_scaled = tf.expand_dims(f0_scaled, axis=-1)\n",
    "    ld_scaled = tf.expand_dims(ld_scaled, axis=-1)\n",
    "    z = tf.reshape(z, shape=(sequence_length, 16))\n",
    "\n",
    "    inputs = {\n",
    "        'pitch': note_number,\n",
    "        'velocity': velocity,\n",
    "        'instrument_source': instrument_source,\n",
    "        'qualities': qualities,\n",
    "        'latent_vector': z\n",
    "    }\n",
    "    \n",
    "    outputs = {\n",
    "        'f0_scaled': f0_scaled,\n",
    "        'ld_scaled': ld_scaled\n",
    "    }\n",
    "\n",
    "    return inputs, outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sharing-wellington",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "natural-intensity",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    _pitch = Input(shape=(1000, 1), name='pitch')\n",
    "    _velocity = Input(shape=(1000, 1), name='velocity')\n",
    "    _instrument_source = Input(shape=(1000, 1), name='instrument_source')\n",
    "    _qualities = Input(shape=(1000, 10), name='qualities')\n",
    "    _latent_sample = Input(shape=(1000, 16), name='latent_vector')\n",
    "    \n",
    "    _input = concatenate([_instrument_source, _qualities, _latent_sample], axis=-1, name='concat_1')\n",
    "    \n",
    "    x = _input\n",
    "    \n",
    "    for i in range(0, 4):\n",
    "        n_filters = 2**(4 + i)\n",
    "        x = Conv1D(n_filters, 5, activation='relu', strides=2, padding='causal', name=f'conv_{i + 1}')(x)\n",
    "        x = MaxPool1D(pool_size=2, name=f'pool_{i + 1}')(x)\n",
    "    \n",
    "    x = Flatten(name='flatten')(x)\n",
    "    \n",
    "    _pitch_x = Reshape((1000, ), name='pitch_reshaped')(_pitch)\n",
    "    _pitch_x = Dense(512, activation='relu', name='pitch_dense_1')(_pitch_x)\n",
    "    _f0_x = concatenate([x, _pitch_x], name='concat_f0')\n",
    "    \n",
    "    _velocity_x = Reshape((1000, ), name='velocity_reshaped')(_velocity)\n",
    "    _velocity_x = Dense(512, activation='relu', name='velocity_dense_1')(_velocity_x)\n",
    "    _ld_x = concatenate([x, _velocity_x], name='concat_ld')\n",
    "    \n",
    "    _f0_scaled = Dense(1000, activation='linear', name='f0_scaled')(_f0_x)\n",
    "    _ld_scaled = Dense(1000, activation='linear', name='ld_scaled')(_ld_x)\n",
    "    \n",
    "    model = tf.keras.models.Model([_instrument_source, _qualities, _latent_sample, _velocity, _pitch],\n",
    "                                  [_f0_scaled, _ld_scaled], name='cc')\n",
    "    return model\n",
    "\n",
    "# Uncomment to export model graph as image\n",
    "# tf.keras.utils.plot_model(create_model(), show_shapes=True, to_file='images/causal_conv_1.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minor-publication",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exclusive-upset",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=3e-4),\n",
    "    loss='mse'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "active-windows",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "total_examples = 32690\n",
    "validation_examples = 2081\n",
    "batch_size = 64\n",
    "steps = int(total_examples / batch_size)\n",
    "validation_steps = int(validation_examples / batch_size)\n",
    "epochs = 1000\n",
    "\n",
    "\n",
    "trainer.train(\n",
    "    model,\n",
    "    dataset_dir='d:/soundofai/complete_data',\n",
    "    model_dir='causal_conv',\n",
    "    epochs=epochs,\n",
    "    features_map=features_map,\n",
    "    steps_per_epoch=steps,\n",
    "    validation_steps=validation_steps,\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mysterious-convertible",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
